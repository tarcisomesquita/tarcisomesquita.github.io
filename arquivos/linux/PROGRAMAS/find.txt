
find . -name 'my*' -print
searches in the current directory and below it, for files and directories with names starting with my.

find . -name "my*" -type f -print
return only files, not return directories and links

find /home -name "my*" -type d -print
return only directories

find . -name "my*" -type f -ls
fornece uma saida semelhante à do comando ls -l

find / -path excluded_path -type f -name myfile -print
This searches every folder on the computer except the subtree excluded_path, for a file with the name myfile.
Não funciona

find . -name "myfile" 2>&1 | grep -v 'Permissão negada'
This example shows how to suppress lines that contain permission denied errors.

find . \( -name "*.htm" -o -name "*.pdf" \) -type f -ls
Find files *.htm OR *.pdf
the operator "or" can be abbreviated as "o".
The "and" operator is assumed where no operator is given.

find /var/ftp/mp3 -name "*.mp3" -type f -exec chmod 644 '{}' \;
For every file whose name ends in .mp3, the command chmod 644 {} is executed replacing {} with the name of the file.
The semicolon indicates the end of the command.

find . -exec grep blah {} ;

If you will be executing over many results, it is more efficient to pipe the results to the xargs command instead. xargs is a more modern implementation, and handles long lists in a more intelligent way. The print0 option can be used with this.

The following command will ensure that filenames with whitespaces are passed to the executed COMMAND without being split up by the shell. It looks complicated at first glance, but is widely used.

find . -print0 | xargs -0 COMMAND

The list of files generated by find (whilst it is being generated) is simultaneously piped to xargs, which then executes COMMAND with the files as arguments. See xargs for more examples and options.
Delete files and directories

Delete empty files and directories and print the names

find /foo -empty -delete -print

Delete empty files

find /foo -type f -empty -delete

Delete empty directories

find /foo -type d -empty -delete

Delete files and directories (if empty) named bad

find /foo -name bad -delete

Warning: -delete should be use with other operators such as -empty or -name.

find /foo -delete  (this deletes all in foo)

Search for a string

This command will search for a string in all files from the /tmp directory and below:

find /tmp -exec grep "search string" '{}' /dev/null \; -print

The /dev/null argument is used to show the name of the file before the text that is found. Without it, only the text found is printed. An equivalent mechanism is to use the "-H" or "--with-filename" option to grep:

find /tmp -exec grep -H "search string" '{}' \; -print

GNU grep can be used on its own to perform this task:

grep -r "search string" /tmp

Example of search for "LOG" in jsmith's home directory

find ~jsmith -exec grep "LOG" '{}' /dev/null \; -print
/home/jsmith/scripts/errpt.sh:cp $LOG $FIXEDLOGNAME
/home/jsmith/scripts/errpt.sh:cat $LOG
/home/jsmith/scripts/title:USER=$LOGNAME

Example of search for the string "ERROR" in all XML files in the current directory and all sub-directories

find . -name "*.xml" -exec grep "ERROR" '{}' \; -print

The double quotes (" ") surrounding the search string and single quotes (' ') surrounding the braces are optional in this example, but needed to allow spaces and other special characters in the string.
Search for all files owned by a user

find . -user <userid>

Search in case insensitive mode

find . -iname "MyFile*"

If the -iname switch is not supported on your system then workaround techniques may be possible such as:

find . -name "[mM][yY][fF][iI][lL][eE]*"

This uses Perl to build the above command for you:

echo "'MyFile*'" |perl -pe 's/([a-zA-Z])/[\L\1\U\1]/g;s/(.*)/find . -name \1/'|sh

Search files by size

Example of searching files with size between 100 kilobytes and 500 kilobytes.

find . -size +100k -a -size -500k

Example of searching empty files.

find . -size 0k

Example of searching non-empty files.

find . -not -size 0k

Search files by name and size

find /usr/src -not \( -name "*,v" -o -name ".*,v" \) '{}' \; -print 
search in the /usr/src directory and all sub directories. All files that are of the form '*,v' ou '.*,v' are excluded.
   -not means the negation of the expression that follows
   \( means the start of a complex expression.
   \) means the end of a complex expression.
   -o means a logical or of a complex expression.

for file in `find /opt \( -name error_log -o -name 'access_log' -o -name 'ssl_engine_log' -o -name 'rewrite_log' -o
-name 'catalina.out' \) -size +300000k -a -size -5000000k`; do cat /dev/null > $file; done

The units should be one of [bckw], 'b' means 512-byte blocks, 'c' means byte, 'k' means kilobytes and 'w' means 2-byte words. The size does not count indirect blocks, but it does count blocks in sparse files that are not actually allocated.
Operators

Operators can be used to enhance the expressions of the find command. Operators are listed in order of decreasing precedence:

    ( expr ) Force precedence.
    ! expr True if expr is false.
    -not expr Same as ! expr.
    expr1 expr2 And (implied); expr2 is not evaluated if expr1 is false.
    expr1 -a expr2 Same as expr1 expr2.
    expr1 -and expr2 Same as expr1 expr2.
    expr1 -o expr2 Or; expr2 is not evaluated if expr1 is true.
    expr1 -or expr2 Same as expr1 -o expr2.
    expr1 , expr2 List; both expr1 and expr2 are always evaluated. The value of expr1 is discarded; the value of the list is the value of expr2.

find . -name 'fileA_*' -or -name 'fileB_*'

This command searches files whose name has a prefix of "fileA_" or "fileB_" in the current directory.

find . -name 'foo.cpp' -not -path '.svn'

This command searches for files with the name "foo.cpp" in all subdirectories of the current directory (current directory itself included) other than ".svn".
See also

    locate, a Unix search tool based on a prebuilt database, and therefore it is faster and less accurate than find (because the database may not be up-to-date).
    mdfind, a similar utility that utilizes metadata for Mac OS X and Darwin
    List of Unix programs
    List of DOS commands
    grep
    find (command), a DOS and Windows command that is very different from UNIX find
    findutils
    tree

===========================================================================================


A Unix/Linux “find” Command Tutorial
©2002–2012 by Wayne Pollock, Tampa Florida USA.  All rights reserved.
Locating Files:

The find command is used to locate files on a Unix or Linux system.  find will search any set of directories you specify for files that match the supplied search criteria.  You can search for files by name, owner, group, type, permissions, date, and other criteria.  The search is recursive in that it will search all subdirectories too.  The syntax looks like this:

find where-to-look criteria what-to-do

All arguments to find are optional, and there are defaults for all parts.  (This may depend on which version of find is used.  Here we discuss the freely available Gnu version of find, which is the version available on YborStudent.)  For example, where-to-look defaults to . (that is, the current working directory), criteria defaults to none (that is, select all files), and what-to-do (known as the find action) defaults to ‑print (that is, display the names of found files to standard output).  Technically, the criteria and actions are all known as find primaries.

For example:

find

will display the pathnames of all files in the current directory and all subdirectories.  The commands

find . -print
find -print
find .

do the exact same thing.  Here's an example find command using a search criterion and the default action:

find / -name foo

This will search the whole system for any files named foo and display their pathnames.  Here we are using the criterion -name with the argument foo to tell find to perform a name search for the filename foo.  The output might look like this:

/home/wpollock/foo
/home/ua02/foo
/tmp/foo

If find doesn't locate any matching files, it produces no output.

The above example said to search the whole system, by specifying the root directory (“/”) to search.  If you don't run this command as root, find will display a error message for each directory on which you don't have read permission.  This can be a lot of messages, and the matching files that are found may scroll right off your screen.  A good way to deal with this problem is to redirect the error messages so you don't have to see them at all:

find / -name foo 2>/dev/null

You can specify as many places to search as you wish:

find /tmp /var/tmp . $HOME -name foo

Advanced Features and Applications:

The “‑print” action lists the names of files separated by a newline.  But it is common to pipe the output of find into xargs, which uses a space to separate file names.  This can lead to a problem if any found files contain spaces in their names, as the output doesn't use any quoting.  In such cases, when the output of find contains a file name such as “foo bar” and is piped into another command, that command “sees” two file names, not one file name containing a space.  Even without using xargs you could have a problem if the file name contains a newline character.

In such cases you can specify the action “‑print0” instead.  This lists the found files separated not with a newline but with a null (or “NUL”) character, which is not a legal character in Unix or Linux file names.  Of course the command that reads the output of find must be able to handle such a list of file names.  Many commands commonly used with find (such as tar or cpio) have special options to read in file names separated with NULs instead of spaces.

Instead of having find list the files, it can run some command for each file found, using the “‑exec” action.  The ‑exec is followed by some shell command line, ended with a semicolon (“;”).  (The semicolon must be quoted from the shell, so find can see it!)  Within that command line, the word “{}” will expand out to the name of the found file.  See below for some examples.

You can use shell-style wildcards in the -name search argument:

find . -name foo\*bar

This will search from the current directory down for foo*bar (that is, any filename that begins with foo and ends with bar).  Note that wildcards in the name argument must be quoted so the shell doesn't expand them before passing them to find.  Also, unlike regular shell wildcards, these will match leading periods in filenames.  (For example “find -name \*.txt”.)

You can search for other criteria beside the name.  Also you can list multiple search criteria.  When you have multiple criteria any found files must match all listed criteria.  That is, there is an implied Boolean AND operator between the listed search criteria.  find also allows OR and NOT Boolean operators, as well as grouping, to combine search criteria in powerful ways (not shown here.)

Here's an example using two search criteria:

find / -type f -mtime -7 | xargs tar -rf weekly_incremental.tar
gzip weekly_incremental.tar

will find any regular files (i.e., not directories or other special files) with the criteria “‑type f”, and only those modified seven or fewer days ago (“‑mtime ‑7”).  Note the use of xargs, a handy utility that coverts a stream of input (in this case the output of find) into command line arguments for the supplied command (in this case tar, used to create a backup archive).

Using the tar option “‑c” is dangerous here;  xargs may invoke tar several times if there are many files found, and each “‑c” will cause tar to over-write the previous invocation.  The “‑r” option appends files to an archive.  Other options such as those that would permit filenames containing spaces would be useful in a “production quality” backup script.

Another use of xargs is illustrated below.  This command will efficiently remove all files named core from your system (provided you run the command as root of course):

find / -name core | xargs /bin/rm -f
find / -name core -exec /bin/rm -f '{}' \; # same thing
find / -name core -delete                  # same if using Gnu find

The last two forms run the rm command once per file, and are not as efficient as the first form, but they are safer if file names contain spaces or newlines.  The first form can be made safer if rewritten to use “‑print0” instead of (the default) “‑print”.  “‑exec” can be used more efficiently (see Using ‑exec Efficiently below), but doing so means running the command once with many file names passed as arguments, and so has the same safety issues as with xargs.

One of my favorite of the find criteria is used to locate files modified less than 10 minutes ago.  I use this right after using some system administration tool, to learn which files got changed by that tool:

find / -mmin -10

(This search is also useful when I've downloaded some file but can't locate it, only in that case “‑cmin” may work better.  Keep in mind neither of these criteria is standard; “‑mtime” and “‑ctime” are standard, but use days and not minutes.)

Another common use is to locate all files owned by a given user (“-user username”).  This is useful when deleting user accounts.

You can also find files with various permissions set.  “-perm /permissions” means to find files with any of the specified permissions on, “-perm -permissions” means to find files with all of the specified permissions on, and “-perm permissions” means to find files with exactly permissions.  Permissions can be specified either symbolically (preferred) or with an octal number.  The following will locate files that are writeable by “others” (including symlinks, which should be writeable by all):

find . -perm -o=w

(Using -perm is more complex than this example shows.  You should check both the POSIX documentation for find (which explains how the symbolic modes work) and the Gnu find man page (which describes the Gnu extensions).

When using find to locate files for backups, it often pays to use the “-depth” option (really a criterion that is always true), which forces the output to be depth-first—that is, files first and then the directories containing them.  This helps when the directories have restrictive permissions, and restoring the directory first could prevent the files from restoring at all (and would change the time stamp on the directory in any case).  Normally, find returns the directory first, before any of the files in that directory.  This is useful when using the “‑prune” action to prevent find from examining any files you want to ignore:

find / -name /dev -prune ...other criteria | xargs tar ...

Using just “find / -name /dev ‑prune | xargs tar ...” won't work as most people might expect.  This says to only find files named “/dev”, and then (if a directory) don't descend into it.  So you only get the single directory name “/dev”!  A better plan is to use the following:

find / ! -path /dev\* |xargs ...

which says find everything except pathnames that start with “/dev”.  The “!” means Boolean NOT.

When specifying time with find options such as ‑mmin (minutes) or ‑mtime (24 hour periods, starting from now), you can specify a number “n” to mean exactly n, “-n” to mean less than n, and “+n” to mean more than n.

Fractional 24-hour periods are truncated!  That means that “find ‑mtime +1” says to match files modified two or more days ago.

For example:

find . -mtime 0   # find files modified between now and 1 day ago
                  # (i.e., within the past 24 hours)
find . -mtime -1  # find files modified less than 1 day ago
                  # (i.e., within the past 24 hours, as before)
find . -mtime 1   # find files modified between 24 and 48 hours ago
find . -mtime +1  # find files modified more than 48 hours ago

find . -mmin +5 -mmin -10 # find files modified between
                          # 6 and 9 minutes ago

Using the (non-standard) “‑printf” action instead of the default “‑print” is useful to control the output format better than you can with the ls or dir utilities.  You can use find with the ‑printf action to produce output that can easily be parsed by other utilities or imported into spreadsheets or databases.  See the Gnu find man page for the dozens of possibilities with the ‑printf action.  (In fact, find with ‑printf is more versatile than ls; it is the preferred tool for forensic examiners even on Windows systems, to list file information.)  For example the following displays non-hidden (no leading dot) files in the current directory only (no subdirectories), with an custom output format:

find ./* -printf "%t %a %c %f \n"
find . -maxdepth 1 -name '[!.]*' -printf 'Name: %16f Size: %6s\n'

“‑maxdepth” is a Gnu extension.  On a modern, POSIX version of find you could use this:

find . -path './*' -prune ...

On any version of find you can use this more complex (but portable) code:

find . ! -name . -prune ...

which says to “prune” (don't descend into) any directories except “.”.

Note that “‑maxdepth 1” will include “.” unless you also specify “‑mindepth 1”.  A portable way to include “.” is:

 find . \( -name . -o -prune \) ...

The “\(” and “\)” are just parenthesis used for grouping, and escaped from the shell.  The “-o” means Boolean OR.

[This information posted by Stephane Chazelas, on 3/10/09 in newsgroup comp.unix.shell.]

As a system administrator, you can use find to locate suspicious files (e.g., world writable files, files with no valid owner and/or group, SetUID files, files with unusual permissions, sizes, names, or dates).  Here's a final more complex example (which I saved as a shell script):

find / -noleaf -wholename '/proc' -prune \
     -o -wholename '/sys' -prune \
     -o -wholename '/dev' -prune \
     -o -wholename '/windows-C-Drive' -prune \
     -o -perm -2 ! -type l  ! -type s \
     ! \( -type d -perm -1000 \) -print

This says to seach the whole system, skipping the directories /proc, /sys, /dev, and /windows-C-Drive (presumably a Windows partition on a dual-booted computer).  The Gnu -noleaf option tells find not to assume all remaining mounted filesystems are Unix file systems (you might have a mounted CD for instance).  The “-o” is the Boolean OR operator, and “!” is the Boolean NOT operator (applies to the following criteria).

So these criteria say to locate files that are world writable (“-perm -2”, same as “-o=w”) and NOT symlinks (“! ‑type l”) and NOT sockets (“! ‑type s”) and NOT directories with the sticky (or text) bit set (“! \( ‑type d -perm -1000 \)”).  (Symlinks, sockets and directories with the sticky bit set are often world-writable and generally not suspicious.)

A common request is a way to find all the hard links to some file.  Using “ls -li file” will tell you how many hard links the file has, and the inode number.  You can locate all pathnames to this file with:

  find mount-point -xdev -inum inode-number

Since hard links are restricted to a single filesystem, you need to search that whole filesystem so you start the search at the filesystem's mount point.  (This is likely to be either “/home” or “/” for files in your home directory.)  The “-xdev” options tells find to not search any other filesystems.

(While most Unix and all Linux systems have a find command that supports the “-inum” criterion, this isn't POSIX standard.  Older Unix systems provided the “ncheck” utility instead that could be used for this.)
Using ‑exec Efficiently:

The ‑exec action takes a command (along with its options) as an argument.  The arguments should contain {} (usually quoted), which is replaced in the command with the name of the currently found file.  The command is terminated by a semicolon, which must be quoted (“escaped”) so the shell will pass it literally to the find command.

To use a more complex action with ‑exec, you can use “sh ‑c complex-command” as the Unix command.  Here's a somewhat contrived example, that for each found file replaces “Mr.” with “Mr. or Ms.”, and also converts the file to uppercase:

   find whatever... -exec sh -c 'sed "s/Mr\./Mr. or Ms./g" "{}" \
     | tr "[:lower:]" "[:upper:]" >"{}.new"' \;

The ‑exec action in find is very useful, but since it runs the command listed for every found file it isn't very efficient.  On a large system this makes a difference!  One solution is to combine find with xargs as discussed above:

  find whatever... | xargs command

However this approach has two limitations.  Firstly not all commands accept the list of files at the end of the command.  A good example is cp:

find . -name \*.txt | xargs cp /tmp  # This won't work!

(Note the Gnu version of cp has a non-POSIX option “‑t” for this, and xargs has options to handle this too.)

Secondly, filenames may contain spaces or newlines, which would confuse the command used with xargs.  (Again Gnu tools have options for that, “find ... ‑print0 | xargs -0 ...”.)

There are POSIX (but non-obvious) solutions to both problems.  An alternate form of ‑exec ends with a plus-sign, not a semi-colon.  This form collects the filenames into groups or sets, and runs the command once per set.  (This is exactly what xargs does, to prevent argument lists from becoming too long for the system to handle.)  In this form the {} argument expands to the set of filenames.  For example:

find / -name core -exec /bin/rm -f '{}' +

This command is equivalent to using find with xargs, only a bit shorter and more efficient.  But this form of ‑exec can be combined with a shell feature to solve the other problem (names with spaces).  The POSIX shell allows us to use:

sh -c 'command-line' [ command-name [ args... ] ]

(We don't usually care about the command-name, so “X”, “dummy”, or “'inline cmd'” is often used.)  Here's an example of efficiently copying found files to /tmp, in a POSIX-compliant way (Posted on comp.unix.shell netnews newsgroup on Oct. 28 2007 by Stephane CHAZELAS):

find . -name '*.txt' -type f \
  -exec sh -c 'exec cp -f "$@" /tmp' X '{}' +

(Obvious, simple, and readable, isn't it?  Perhaps not, but worth knowing since it is safe, portable, and efficient.)
Common “Gotcha”:

If the given expression to find does not contain any of the “action” primaries ‑exec, -ok, or ‑print, the given expression is effectively replaced by:

find \( expression \) -print

The implied parenthesis can cause unexpected results.  For example, consider these two similar commands:

$ find -name tmp -prune -o -name \*.txt
./bin/data/secret.txt
./tmp
./missingEOL.txt
./public_html/graphics/README.txt
./datafile2.txt
./datafile.txt

$ find -name tmp -prune -o -name \*.txt -print
./bin/data/secret.txt
./missingEOL.txt
./public_html/graphics/README.txt
./datafile2.txt
./datafile.txt

The lack of an action in the first command means it is equivalent to:

find . \( -name tmp -prune -o -name \*.txt \) -print

This causes tmp to be included in the output.  However for the second find command the normal rules of Boolean operator precedence apply, so the pruned directory does not appear in the output.

The find command can be amazingly useful.  See the man page to learn all the criteria and actions you can use.

 

= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 


Example uses of the Linux Command find
An Introductory Tutorial

By Juergen Haas, About.com Guide
Ads:

    Red Hat Linux
    Linux
    Fedora Linux Server
    For Linux Command Line
    Linux Developer Tools

Ads

Anuncie com o GoogleServices.Google.com/AwCreditosPromoEscolha seu orçamento e anúncio. Comece a anunciar online hoje.

Automatize tarefaswww.4linux.com.brUtilizando scripts com as linguagens BASH, Perl e Python.

ca2 C++ APIca2.ccUse esta API em seus programas C++.
Linux Ads

    Red Hat Linux
    Linux
    Fedora Linux Server
    For Linux Command Line
    Linux Developer Tools

Ads

Imóveis em Juquehywww.suacasaemjuquei.com.brCasas em condomínio alto padrão em Juquehy por R$250 mil de entrada

Traduza Qualquer Tutorialwww.Babylon.comPrograma Tradutor 100% Gratuito! Aproveite e Baixe Agora Mesmo.
The following examples illustrate typical uses of the command find for finding files on a computer.

 find / -name game

Looks for a file named "game" starting at the root directory (searching all directories including mounted filesystems). The `-name' option makes the search case sensitive. You can use the `-iname' option to find something regardless of case.

 find /home -user joe

Find every file under the directory /home owned by the user joe.

 find /usr -name *stat

Find every file under the directory /usr ending in "stat".

 find /var/spool -mtime +60

Find every file under the directory /var/spool that was modified more than 60 days ago.

 find /tmp -name core -type f -print | xargs /bin/rm -f

Find files named core in or below the directory /tmp and delete them. Note that this will work incorrectly if there are any filenames containing newlines, single or double quotes, or spaces.

 find /tmp -name core -type f -print0 | xargs -0 /bin/rm -f

Find files named core in or below the directory /tmp and delete them, processing filenames in such a way that file or directory names containing single or double quotes, spaces or newlines are correctly handled. The -name test comes before the -type test in order to avoid having to call stat(2) on every file.

 find . -type f -exec file '{}' \;

Runs `file' on every file in or below the current directory. Notice that the braces are enclosed in single quote marks to protect them from interpretation as shell script punctuation. The semicolon is similarly protected by the use of a backslash, though ';' could have been used in that case also.

find / \( -perm -4000 -fprintf /root/suid.txt '%#m %u %p\n' \), \
 \( -size +100M -fprintf /root/big.txt '%-10s %p\n' \)

Traverse the filesystem just once, listing setuid files and directories into /root/suid.txt and large files into /root/big.txt.

 find $HOME -mtime 0

Search for files in your home directory which have been modified in the last twenty-four hours. This command works this way because the time since each file was last modified is divided by 24 hours and any remainder is discarded. That means that to match -mtime 0, a file will have to have a modification in the past which is less than 24 hours ago.

 find . -perm 664

Search for files which have read and write permission for their owner, and group, but which other users can read but not write to. Files which meet these criteria but have other permissions bits set (for example if someone can execute the file) will not be matched.

 find . -perm -664

Search for files which have read and write permission for their owner and group, and which other users can read, without regard to the presence of any extra permission bits (for example the executable bit). This will match a file which has mode 0777, for example.

 find . -perm /222

Search for files which are writable by somebody (their owner, or their group, or anybody else).

 find . -perm /220
 find . -perm /u+w,g+w
 find . -perm /u=w,g=w

All three of these commands do the same thing, but the first one uses the octal representation of the file mode, and the other two use the symbolic form. These commands all search for files which are writable by either their owner or their group. The files don't have to be writable by both the owner and group to be matched; either will do.

 find . -perm -220
 find . -perm -g+w,u+w

Both these commands do the same thing; search for files which are writable by both their owner and their group.

 find . -perm -444 -perm /222 ! -perm /111
 find . -perm -a+r -perm /a+w ! -perm /a+x

These two commands both search for files that are readable for everybody (-perm -444 or -perm -a+r), have at least on write bit set (-perm /222 or -perm /a+w) but are not executable for anybody (! -perm /111 and ! -perm /a+x respectively) 


= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 

Introduction

See also
Softpanorama find page
Recommended Links
Man pages
Examples
xargs
tar
cpio

The idea behind find  is extremely simple: this is a utility for searching files using the directory information. Despite simplicity of the idea Unix find  is a pretty tricky and often fool even experienced UNIX professionals with ten on more years of sysadmins work under the belt.

Find is useful not only as search instrument, but also can enhance functionality of those Unix utilities that do not include tree traversal. BTW few know that GNU grep has -r option for this purpose that can be used to perform simple tree traversal tasks, for example grep -r "search string" /tmp.).

There are several versions of find  with the main two being POSIX find  used in Solaris, AIX, etc and GNU find  used in linux. GNU find was written by Written by Eric B. Decker, James Youngman, and Kevin Dalley. Version 4.5 or later is recommended. Unfortunately as of version 4.5 find still does not support  Perl-style regular expressions, but you can use AWK regex or egrep regex.

GNU find  can be installed on Solaris and AIX and it can be recommended as it is more powerful, more flexible utility; additional capabilities that GNU fin has are often quite useful. For sysadmin it is better to have a good knowledge of one utility then mediocre knowledge of two similar but with subtle difference implementations of find (devil is in details).

The popularity of find  is related to the fact that it can do more then a simple tree traversal available with option -r  (or -R) in many Unix utilities. Unix does not have central database of installed files so this information needs to be collected on the fly. Traversal of directory tree provided by find  is very flexible and you can have excluded tree branches, select files or directories using regular expressions. It also can be limited to specific typed of filesystem. Those capabilities are far superior to built-in tree traversal that many Unix utilities provide. In this sense find is a nice example of Unix component philosophy. It not only performs the main function it was designed for, but can serve as an enhancer of functionally of other utilities including utilities that do not have capability to traverse the directory tree.

For obscure historical reasons find mini-language is completely different from all other UNIX commands: it uses full-word options rather than single-letter options. For example, instead of a typical Unix-style option -f to match filenames (like in tar -xvf mytar.tar) find uses option -name. With the advent of scripting languages this idiosyncratic mini-language for specifying queries probably outlived its usefulness, but nobody has courage to enhance find adding a standard scripting language as a macro language: find is way too entrenched in Unix to be easily replaced with something better. Unix still does not has a standard macrolanguage so, for example, adding Lua as a macrolanguage might be a bad idea if it popularity wane and other similar language dominant.
Search root

The first argument for find is the directory to search (search root in find terminology). It important to understand that search root can consist of multiple directories, for example:

find /usr /bin /sbin /opt -name sar # No /proc /tmp /var

In the example above we exclude non-relevant directories from the list of second level Unix directories that contain binaries. Searching for a binary that is not in the path is a frequent operation for most unix administrators so creating an alias or function for this purpose makes perfect sense. For example, a simple function that allow n search executables can look like:

function myfind {
    find /usr /bin /sbin /opt -name "$1*" -type f -ls
}

The list of directories to search can also be generated by script, for example

find `gen_root_dirs.sh` -type f -size 0 -ls # find files with zero size

Here we assume gen_root_dirs.sh  returns the list of directories in which we can perform the search specified.
Search expression

After the list of directories to search find expects so called "search expression". In other words, the first argument starting with "-" is considered to be a start of "search expression".

Search expression can be quite complex and contain several parts connected with -or  predicate. Each component of search expression is evaluated to true or false and used to determine whether the file in question satisfy the expression or not. Some components like -exec have side effects.

By default individual elements are assumed to be connected with AND predicate so all of them need to be true to list the file in the results. For example to look across the /usr/local and /var/www/html directory trees for filenames that contain the pattern "*.?htm*", you can use the following command:

    find /usr /var/html -name "*.?htm*" -type f

Please note that you need quotes for any regex. Otherwise *htm*  it will be evaluated immediately in the current context by shell. Find can use several types of regular expressions. Default is simple regex (or DOS-style regex, if you wish).

It is difficult to remember all the details of this language unless you construct complex queries each day and that's why this page was created. Sometimes errors and miscalculations in constructing find  search expression lead to real disasters when find is used to execute commands like rm, chown, chmod  (via -exec option, see below). You can wipe substantial part of directory tree or change attributes of system files, if you are not careful.

So the first rule of using find  is never execute complex query against the filesystem with -exec  option. First use -ls  option to see what files will be picked up and only then convert it into -exec. Of course in a hurry and under pressure all rules go down the toilet, but still it make sense to remember this simple rule. Please read Typical Errors in using find. It might help you to avoid some of the most nasty errors.
Never try to execute complex find query with -exec  option without first testing the result by replacing -exec  option with -ls  option. Please read Typical Errors in using find. It might help you to avoid some of the most nasty errors.

Along with this page it make sense to consult the list of typical (and not so typical) examples which can be found in in Examples page on this site as well as in the links listed in Webliography.

An excellent paper Advanced techniques for using the UNIX find command was written by Bill Zimmerly. I highly recommend to read it and print for the reference. Several examples in this tutorial are borrowed from the article.
An excellent paper Advanced techniques for using the UNIX find command was written by Bill Zimmerly. I highly recommend to read it and then print for a reference. Several examples in this tutorial are borrowed from the article. 	
Predicates and options of the search expression

The full search expression language contains several dozens of different predicates and options. There are two versions of this language:

    Version implemented in POSIX find
    Version implemented in GNU find which is a superset of POSIX find.

GNU find is preferable and can make a difference in complex scripts. But for interactive use the differences is minor: only small subset of options is typically used on day-to-day basis by system administrators. Among them:

    -name True if pattern matches the current file name. Simple regex (shell patterns) may be used. it should be in quotes to prevent shell expansion. A backslash (\) is used as an escape character within the pattern. The pattern should be escaped or quoted. If you need to include parts of the path in the pattern in GNU find you should use predicate -wholename If you need to use regular expressions you need to use predicates regextype and regex (only GNU find)

    Use the -iname  predicate (only GNU find supports it) to run a case-insensitive search, rather than just -name. For example:

    find . -follow -iname '*.htm' -print0 | xargs -i -0 mv '{}' ~/webhome

    Usage of -print0  is an insurance for the correct processing of files with spaces.
    -fstype  type True if the filesystem to which the file belongs is of type type. For example on Solaris mounted local filesystems have type ufs (Solaris 10 added zfs). For AIX local filesystems are typically jfs2 (journalled file system). If you want to traverse NFS filesystems you can use nfs (network file system). If you want to avoid traversing network and special filesystems you should use predicate local  and in certain circumstances mount
    "-atime/-ctime/-mtime"  [+|-]n Each of those specifies selection of the files based on three Unix timestamps: the last time a files's "access time", "file status" and "modification time".  Here n is time interval -- an integer with optional sign. It is measured in 24-hour periods (days) or minutes (GNU find only) counted from the current moment. Period can be used without sign or with plus of minus sign. The meaning of those three possibilities are as following:
        n: exactly n 24-hour periods (days) ago, 0 means today.
        +n: "more then n 24-hour periods (days) ago", or older then n,
        -n: less than n 24-hour periods (days) ago (-n), or younger then n. It's evident that -1, and 0 are the same and both means "today".

    Note: Gnu find provides the ability to use minutes as a unit instead of hours, for example if you want to find what was changed during the installation of particular package you can try (assuming that installation took 3 min):

    find / -mmin -3

    Examples
        Find everything in your home directory modified in the last 24 hours:

        find $HOME -mtime -1

        Find everything in your home directory modified in the last 30 min

        find $HOME -mmin -30

        Find files in your home directory that were NOT been modified a year or more:

        find $HOME -mtime +365

        To find html files that have been modified in the last seven 24-hour periods (days), I can use -mtime  with the argument -7 (include the hyphen):

        find . -mtime -7 -name "*.html" 

        If you use the number 1 (without a hyphen), find will match only html files that were modified exactly one day (24-hour period) ago:

        find . -mtime 1 -name "*.html" -print

        -newer/-anewer/-cnewer  baseline_file The time of modification, access time or creation time are compared with the same timestamp in the baseline file. If file is a symbolic link and the -H option or the -L option is in effect, the modification time of the file it points to is always used.
            -newer Modification time is compared with modification time of the baseline_file. True if file was modified more recently than baseline_file.
            -anewer  Access time is compared with access time of baseline_file. True if file was last accessed more recently than baseline file.
            -cnewer Creation time is compared. For example: find everything in your home directory that has been modified more recently than "~joeuser/lastbatch.txt ":

                find $HOME -newer ~joeuser/lastbatch.txt

        -delete Delete files or directories; true if removal succeeded. If the removal failed, an error message is issued. As deleted files are difficult to recover, you are strongly advised  test the command substituting it first with -ls, especially if you try to delete files from system or other directories. Five minutes testing often saves five hours frantic recovery effort ;-). This option also can be used for deleting files with "strange" characters in names.  First, determine the file or directory's inode. For example

        ls -lhi *.html

        Then use the find command with the inode of the troublemaker, for example:

        find . -type f -inum 31467125 -exec mv {} new_name.html \;

        To simply delete such a file you can use option -delete of GNU find:

        find . -type f -inum 314167125 -delete

        The same trick can be used for renaming files with special characters in names. See  How to rename files with special characters in names.
         
        -exec command Executes the specified command for each file found. This is the most powerful (and thus dangerous) option that find provides. This option is more suitable for executing relatively simple commands. {}  species the current file which is expanded to a relative path starting with the name of one of the starting directories, rather than just the basename of the matched file. You can use several instances of {} in the command: GNU find replaces {} wherever it appears. For more complex things post processing of output of find command with xargs  is a safer option as you can check the output first before running some potentially irreversible action on those files. For examples and mode detailed coverage see Using -exec option with find
        -local True if the file system type is not a remote file system type. In Solaris those types are defined in the /etc/dfs/fstypes file. nfs  is used as the default remote filesystem type if the /etc/dfs/fstypes file is not present. The -local  option skips the hierarchy of non-local directories. You can also search without descending more then certain number of levels as explained later or exclude some directories from the search using
        -mount  Always true. Restricts the search to the file system containing the directory specified. Does not list mount points to other file systems.
        -xdev  Same as the -mount primary. Always evaluates to the value True. Prevents the find  command from traversing a file system different from the one specified by the Path parameter.
        -xattr  True if the file has extended attributes.
        -wholename  simple-regex [GNUfindonly] . File name matches simple regular expression (often called shell patterns). In simple regular expressions the metacharacters '/' and '.' do not exist; so, for example, you can specify:

            find . -wholename '/lib*'

        which will print entries from directories /lib64  and /lib. To ignore the directories specified, use option -prune For example, to skip the directory /proc  and all files and directories under it (which is important for linux as otherwise errors are produced you can something like this:

        find . -wholename '/proc/*' -prune -o -name file_to_be_found		

        If you administer a lot of linux boxes it is better to create function like:

        function fff {
           if [[ `uname` == "Linux" ]] ; do 
              alias fff='find . -wholename '/proc/*' -prune -o -name '
           else
              fff='find . -name ' # non GNUfinddoes not support -wholename
           fi
        }

    Other useful options of the find command include:
        -regex regex [GNU find only] File name matches regular expression. This is a match on the whole pathname not just a filename. Predicate "-iregex" option provides the capability to ignore case.

        The default regular expressions understood by find are Emacs Regular Expressions. This can be changed with the -regextype option. Currently implemented regex types are:
            emacs (the default),
            posix-awk,
            posix-basic,
            posix-egrep and
            posix-extended.

        I hope somebody adds Perl regex soon. That's really unfortunate the FSF dropped the ball here.
        -perm permissions   Locates files with certain permission settings. Often used for finding world-writable files or SUID files. See separate page devoted to the topic
        -user Locates files that have specified ownership. Option -nouser locates files without ownership. For such files no user in /etc/passwd corresponds to file's numeric user ID (UID). such files are often created when tar of sip archive is transferred from other server on which the account probably exists under a different UID)
        -group Locates files that are owned by specified group. Option -nogroup means that no group corresponds to file's numeric group ID (GID) of the file. This is useful option for server cleanup, as with time structure of the groups changes but some file remain in now defunct groups. Also files and tar balls downloaded by root from other servers might have numeric groups that have no match on the box.
        -size Locates files with specified size. -size attribute lets you specify how big the files should be to match. You can specify your size in kilobytes and optionally also use + or - to specify size greater than or less than specified argument. For example:

        find /home -name "*.txt" -size 100k
        find /home -name "*.txt" -size +100k
        find /home -name "*.txt" -size -100k

        The first brings up files of exactly 100KB, the second only files greater than 100KB, and the last only files less than 100KB.
        -ls  list current file in ls -dils  format on standard output.
         
        -type Locates a certain type of file. The most typical options for -type  are as following:
            d - Directory
            f - File
            l - Link

        For example, to limit search to directories use can use the -type d specifier. Here's one example:

        find . -type d -print

    As a syntax helper one can use a web form for generating search expression. Unix find command helper. In no way that means that you can skip testing, especially if you plan to use option -exec. Such web forms are purely syntax helpers. It is testing (and only testing) that can reveal some nasty surprises in what you thought is a perfectly correct search expression. 

Part 2: Find search expressions

Unix find uses its special "search expressions" language to define complex conditions to  locate or ignore particular files and directories.

Search expressions consist of multiple predicates (atomic expressions that evaluate to true or false) connected by classic Boolean logic operations AND or OR or NOR.

    a  -- to have multiple conditions connected using logical AND.  It is the default connector of individual search terms and explicit AND predicate is rarely used.

    You can also specify as many conditions as you want to be connected with AND. For example, if you want to find the list of files that have been modified in the last 24 hours and have  permission set to 777 (world-writable files), you would execute the following command:

        find . -perm 777  -mtime 0 -print

        Which is the same as:

        find . -perm 777 -a -mtime 0 -a -print

    o  -- to have multiple conditions connected using logical OR. Usually in used in brackets to ensure proper order of evaluation. For example \(-perm -4000 -o -perm -2000 \)
    !  -- to negate a condition (logical NOT) . NOT should be specified with a backslash before exclamation point ( \! ). For example

    find . \! -name "*.gz" -exec gzip {} \;

By default search terms in find expressions are concatenated using AND predicate

The simplest "find search expression" is just one predicate. for example here is how to list all sub-trees of the current directory:

find . -print

As you can see in this case 'search expression consist of just one predicate (-print). Predicate -print always returns value TRUE, so each file will be printed.  For example, if the system administrator want a list of .profile  used by all users, the following command should be executed:

find / -name .profile -print

Here two predicates are connected by implicit AND operation. Another example of expression with two predicate expression is the expression the finds a list of all files (but not directories) modified in the last 24 hours:

    find . -mtime 0 -type f

More complex search expression can contain sub-expressions in parentheses which makes "find search language" somewhat similar to regular algebraic expressions.  As parentheses have a special meaning in Unix shell, they should be prefixed with the escape symbol "\"  or used inside single quotes as '(' and ')'. You cannot use single quotes around the entire expression as the find  command interpret it as a single element of search expression.  Typically \( expression \)  --  "escaped parentheses" are used to define any composite condition. For example

find / -type f \( -perm -4000 -o -perm -2000 \) -exec ls -l {} \; 

This example shows that the same predicate can be used in find multiple times.  Any predicate.

The same predicate can be used multiple times connected by AND or OR. In case of -name predicate such usage can simplify regular expressions

For example name can be used this way. In case of -name  predicate such usage can simplify regular expressions. For example:

find / -type f \( -name "*.xls" -o -name "*.csv" \) -exec ls -l {} \;

is simpler then:

find / -regex ".*\.\(xls\|csv\)"

The find command checks the specified predicates and sub-expressions, going from left to right, once for each file or directory encountered.  Here sub-expression \( -perm -4000 -o -perm -2000 \)  is evaluated after the predicate -type f  but before the predicate "-exec ls -l {} \;" 

art 3: Finding files using file name or path

Find development processes thru several generations and each left certain mark on its ability to use regular expressions. As of August 2011 it still cannot use Perl regular expression, though.

    Name predicate and shell patterns
    Searching fully qualified file name and path
    Regular expressions

Name predicate and shell patterns
The first and probably the most popular option is -name shell_pattern It is true if the basename of the file (with the path removed) matches the shell pattern specified. Predicate -iname pattern is the same thing only case insensitive. For example to find files with the extension .conf in /etc/ directory:

find /etc -name '*.conf'

Note: To ignore a subtree you can use -prune  .
Searching fully qualified file name and path
Using -path  shell_pattern you can search a full path of the file instead of its name.

More useful is predicate -wholename  which searches the path+name(path is from start of the search so this not afully qualified file name).

Predicates -ipath  and -iwholename  are similar but in the latter case the match is case-insensitive.

    Note: For predicates -path  , -wholename, -ipath  and -wholename  , a path is consists of all the directories traversed from find's start point to the file being tested, followed by the base name of the file itself. Only if search starts from the root directory these it will be equal to absolute paths

For example

cd /tmp
mkdir -p foo/bar/baz
find foo -path foo/bar -print foo/bar # first find command
find foo -path /tmp/foo/bar -print # the second find command (prints nothing)
find /tmp/foo -path /tmp/foo/bar -print /tmp/foo/bar # the third find command

Notice that due to search starting point foo  the second find  command prints nothing, even though /tmp/foo/bar  exists.

Unlike file name expansion on the command line, a *  in the pattern will match both /  and leading dots in file names:

find .  -path '*f'
./quux/bar/baz/f
find .  -path '*/*config'
./quux/bar/baz/.config

Regular expressions

Find defaults to basic regular expressions (DOS style regex or shell pattern matching). Here is the quote from GNU find manual (Finding Files)

    find and locate can compare file names, or parts of file names, to shell patterns. A shell pattern is a string that may contain the following special characters, which are known as wildcards or metacharacters.

    You must quote patterns that contain metacharacters to prevent the shell from expanding them itself. Double and single quotes both work; so does escaping with a backslash.

    *
        Matches any zero or more characters.
         
    ?
        Matches any one character.
         
    [string]
        Matches exactly one character that is a member of the string string. This is called a character class. As a shorthand, string may contain ranges, which consist of two characters with a dash between them. For example, the class [a-z0-9_]  matches a lowercase letter, a number, or an underscore. You can negate a class by placing a !  or ^  immediately after the opening bracket. Thus, [^A-Z@]  matches any character except an uppercase letter or an at sign.
         
    \
        Removes the special meaning of the character that follows it. This works even in character classes. 

    In the find tests that do shell pattern matching ( -name  , -wholename  , etc.), wildcards in the pattern will match a .  at the beginning of a file name. This is also the case for locate. Thus, find -name '*macs'  will match a file named .emacs, as will locate '*macs'  .

    Slash characters have no special significance in the shell pattern matching that find and locate do, unlike in the shell, in which wildcards do not match them. Therefore, a pattern foo*bar  can match a file name foo3/bar  , and a pattern ./sr*sc  can match a file name ./src/misc  .

    If you want to locate some files with the locate  command but don't need to see the full list you can use the --limit  option to see just a small number of results, or the --count  option to display only the total number of matches.

Type of regular expression that find will use can be specified with option -regextype. In best GNU traditions you need to select from several option, only half of which are useful (see Finding Files)

    findutils-default. Default behavior if  -regex  or -iregex  is specified, but  option -regextype is not .
        The character ‘.’ matches any single character.

        ‘+’
            indicates that the regular expression should match one or more occurrences of the previous atom or regexp.
             
        ‘?’
            indicates that the regular expression should match zero or one occurrence of the previous atom or regexp.
             
        ‘\+’
            matches a ‘+’
             
        ‘\?’
            matches a ‘?’. 

        Bracket expressions are used to match ranges of characters. Bracket expressions where the range is backward, for example ‘[z-a]’, are ignored. Within square brackets, ‘\’ is taken literally. Character classes are not supported, so for example you would need to use ‘[0-9]’ instead of ‘[[:digit:]]’.
        GNU extensions are supported:
            ‘\w’ matches a character within a word
            ‘\W’ matches a character which is not within a word
            ‘\<’ matches the beginning of a word
            ‘\>’ matches the end of a word
            ‘\b’ matches a word boundary
            ‘\B’ matches characters which are not a word boundary
            ‘\`’ matches the beginning of the whole input
            ‘\'’ matches the end of the whole input
        Grouping is performed with backslashes followed by parentheses ‘\(’, ‘\)’. A backslash followed by a digit acts as a back-reference and matches the same thing as the previous grouped expression indicated by that number. For example ‘\2’ matches the second group expression. The order of group expressions is determined by the position of their opening parenthesis ‘\(’.
        The alternation operator is ‘\|’.
        The character ‘^’ only represents the beginning of a string when it appears:
            At the beginning of a regular expression
            After an open-group, signified by ‘\(’
            After the alternation operator ‘\|’
        The character ‘$’ only represents the end of a string when it appears:
            At the end of a regular expression
            Before a close-group, signified by ‘\)’
            Before the alternation operator ‘\|’
        ‘*’, ‘+’ and ‘?’ are special at any point in a regular expression except:
            At the beginning of a regular expression
            After an open-group, signified by ‘\(’
            After the alternation operator ‘\|’
        The longest possible match is returned; this applies to the regular expression as a whole and (subject to this constraint) to subexpressions within groups.
         
        egrep.  This is the second useful option as most sysadmin know egreo well.

            The character ‘.’ matches any single character except newline.

            ‘+’
                indicates that the regular expression should match one or more occurrences of the previous atom or regexp.
                 
            ‘?’
                indicates that the regular expression should match zero or one occurrence of the previous atom or regexp.
                 
            ‘\+’
                matches a ‘+’
                 
            ‘\?’
                matches a ‘?’. 

            Bracket expressions are used to match ranges of characters. Bracket expressions where the range is backward, for example ‘[z-a]’, are ignored. Within square brackets, ‘\’ is taken literally. Character classes are supported; for example ‘[[:digit:]]’ will match a single decimal digit. Non-matching lists ‘[^...]’ do not ever match newline.

            GNU extensions are supported:
                ‘\w’ matches a character within a word
                ‘\W’ matches a character which is not within a word
                ‘\<’ matches the beginning of a word
                ‘\>’ matches the end of a word
                ‘\b’ matches a word boundary
                ‘\B’ matches characters which are not a word boundary
                ‘\`’ matches the beginning of the whole input
                ‘\'’ matches the end of the whole input

            Grouping is performed with parentheses ‘()’. A backslash followed by a digit acts as a back-reference and matches the same thing as the previous grouped expression indicated by that number. For example ‘\2’ matches the second group expression. The order of group expressions is determined by the position of their opening parenthesis ‘(’.

            The alternation operator is ‘|’.

            The characters ‘^’ and ‘$’ always represent the beginning and end of a string respectively, except within square brackets. Within brackets, ‘^’ can be used to invert the membership of the character class being specified.

            The characters ‘*’, ‘+’ and ‘?’ are special anywhere in a regular expression.

            The longest possible match is returned; this applies to the regular expression as a whole and (subject to this constraint) to subexpressions within groups.

        posix-awk  Regular expressions compatible with the POSIX awk command (not GNU awk). Useful for heavy awk users:

            The character ‘.’ matches any single character except the null character.

            ‘+’
                indicates that the regular expression should match one or more occurrences of the previous atom or regexp.
                 
            ‘?’
                indicates that the regular expression should match zero or one occurrence of the previous atom or regexp.
                 
            ‘\+’
                matches a ‘+’
                 
            ‘\?’
                matches a ‘?’. 

            Bracket expressions are used to match ranges of characters. Bracket expressions where the range is backward, for example ‘[z-a]’, are invalid. Within square brackets, ‘\’ can be used to quote the following character. Character classes are not supported, so for example you would need to use ‘[0-9]’ instead of ‘[[:digit:]]’.

            GNU extensions are not supported and so ‘\w’, ‘\W’, ‘\<’, ‘\>’, ‘\b’, ‘\B’, ‘\`’, and ‘\'’ match ‘w’, ‘W’, ‘<’, ‘>’, ‘b’, ‘B’, ‘`’, and ‘'’ respectively.

            Grouping is performed with parentheses ‘()’. An unmatched ‘)’ matches just itself. A backslash followed by a digit matches that digit.

            The alternation operator is ‘|’.

            The characters ‘^’ and ‘$’ always represent the beginning and end of a string respectively, except within square brackets. Within brackets, ‘^’ can be used to invert the membership of the character class being specified.

            ‘*’, ‘+’ and ‘?’ are special at any point in a regular expression except:
                At the beginning of a regular expression
                After an open-group, signified by ‘(’
                After the alternation operator ‘|’

            The longest possible match is returned; this applies to the regular expression as a whole and (subject to this constraint) to subexpressions within groups.

        posix-basic  POSIX Basic Regular Expressions. It's probably the most popular type often called shell patterns and used by default in -name predicate
            *  Matches any zero or more characters.
            ?  Matches any one character.
            [string]  Matches exactly one character that is a member of the string string. This is called a character class. As a shorthand, string may contain ranges, which consist of two characters with a dash between them. For example, the class [a-z0-9_]  matches a lowercase letter, a number, or an underscore. You can negate a class by placing a !  or ^  immediately after the opening bracket. Thus, [^A-Z@]  matches any character except an uppercase letter or an at sign.
            \  Removes the special meaning of the character that follows it. This works even in character classes
        posix-egrep  Regular expressions compatible with the POSIX egrep command
        posix-extended  POSIX Extended Regular Expressions.
        emacs  Useful for heavy users of Emacs.   

    See Regular Expressions for more information on the regular expression dialects...  There are many books about regular expressions that provide a good guidance into this esoteric area. See Best books about Regular Expressions
    The regular expression itself can be specified using -regex option (or -iregex option which ignores case). You must quote patterns that contain metacharacters to prevent the shell from expanding them itself. Double and single quotes both work; so does escaping with a backslash. 

Part 4: Selecting files using their age

Find permits selection of files based on Unix mtime, ctime, and atime attributes.  The standard unit is 24 hour periods (a day). GNU find also permits using minutes for the period, for example:

find / -mmin -10

Those are pretty useful capabilities, especially mtime. For example, if you forget where you downloaded a file you can try to find it using: 

$ find ~ -type f -mtime 0

All find standard predicates that work with age of the file use 24 hour periods (a day)

Parameter n is time interval -- an integer with optional sign. It is measured in 24-hour periods (days) or minutes counted from the current moment.

    n:  If the integer n does not have sign this means exactly n 24-hour periods (days) ago, 0 means today.
    +n:  If it has plus sing, then it means "more then n 24-hour periods (days) ago", or older then n,
    -n:  If it has the minus sign, then it means less than n 24-hour periods (days) ago (-n), or younger then n. It's evident that -1 and 0 are the same and both means "today".

Examples:

    Find everything in your home directory modified in the last 24 hours:

    find $HOME -mtime -1 

    Find everything in your home directory modified in the last seven 24-hour periods (days):

    find $HOME -mtime -7

    Find everything in your home directory that have NOT been modified in the last year:

    find $HOME -mtime +365 

    To find html files that have been modified in the last seven 24-hour periods (days), I can use -mtime  with the argument -7 (include the hyphen):

     find . -mtime -7 -name "*.html" -print 

    Note: If you use the number 7 (without a hyphen), find will match only html files that were modified exactly seven 24-hour periods (days) ago:

    find . -mtime 7 -name "*.html" -print

    To find those html files that were not touched for at least seven 24-hour periods (days),  use +7:

    find . -mtime +7 -name "*.html" -print 

Unix keeps track of three timestamps. Of them atime  is the simplest the non-controversial: it stands for access time which is when the file was last read.

It is important to understand the precise meaning of  ctime  and mtime  timestamps. The most common misconception here is to view  ctime as file "creation time". It is actually "change time". Here are more formal explanations: 

    ctime is the inode change time. When does the inode change, when you of course update a file, but also when you do things like changing the permissions of the file but not necessarily its contents. It would ne better to call this attribute change time as it indicates the last time a file’s metadata (inode) was changed.  ctime  changes when you change file's ownership or access permissions. As the man page for stat explains: “The field st_ctime is changed by writing or by setting inode information (i.e., owner, group, link count, mode, etc.).”
     
    mtime: is the "content modification time", so if you change the contents of the file, this timestamp is updated. Changes of name, ownership and permissions does not affect it 

For a given file ctime  and mtime  can be different depending on if you just modified the inode or the contents of the file (which updates ctime as well). Commands like chown, chmod,  and ln  change only ctime.  Touch command change only mtime. For example if you need to change the date to Jun 21, 2008 9AM to example.txt, then you can go (-t parameter in touch has format [[CC]YY]MMDDhhmm[.SS]):

touch -t 200907210900 example.txt 

The second important thing to understand that unless -daystart  option is used [Gnu find only], time in Unix find is measured in 24 hour periods (fractions are allowed in GNU find) from the current moment.
Unless -daystart option is used [Gnu find only], time in Posix find is measured in 24 hour periods from the current moment

Those 24 hours periods are usually called "days" but the definition of "days" used in find is different from common usage  (calendar days are typically understood as 24 hour periods starting at midnight). The "day" in "find language" is interpreted as "24 hour periods starting from the current time". Here is how working with time ranges described in GNU find documentation  (Finding Files)

    2.3.1 Age Ranges

    These tests are mainly useful with ranges (‘+n’ and ‘-n’).
    — Test: -atime n
    — Test: -ctime n
    — Test: -mtime n

        True if the file was last accessed (or its status changed, or it was modified) n*24 hours ago. The number of 24-hour periods since the file's timestamp is always rounded down; therefore 0 means “less than 24 hours ago”, 1 means “between 24 and 48 hours ago”, and so forth. Fractional values are supported but this only really makes sense for the case where ranges (‘+n’ and ‘-n’) are used.

    — Test: -amin n
    — Test: -cmin n
    — Test: -mmin n

        True if the file was last accessed (or its status changed, or it was modified) n minutes ago. These tests provide finer granularity of measurement than ‘-atime’ et al., but rounding is done in a similar way (again, fractions are supported). For example, to list files in /u/bill that were last read from 2 to 6 minutes ago:

                  find /u/bill -amin +2 -amin -6

    — Option: -daystart

        Measure times from the beginning of today rather than from 24 hours ago. So, to list the regular files in your home directory that were modified yesterday, do

                  find ~/ -daystart -type f -mtime 1

        The ‘-daystart’ option is unlike most other options in that it has an effect on the way that other tests are performed. The affected tests are ‘-amin’, ‘-cmin’, ‘-mmin’, ‘-atime’, ‘-ctime’ and ‘-mtime’. The ‘-daystart’ option only affects the behavior of any tests which appear after it on the command line.

    2.3.2 Comparing Timestamps
    — Test: -newerXY reference
     

        Succeeds if timestamp ‘X’ of the file being considered is newer than timestamp ‘Y’ of the file reference. The letters ‘X’ and ‘Y’ can be any of the following letters:

        ‘a’
            Last-access time of reference
             
        ‘B’
            Birth time of reference (when this is not known, the test cannot succeed)
             
        ‘c’
            Last-change time of reference
             
        ‘m’
            Last-modification time of reference
             
        ‘t’
            The reference argument is interpreted as a literal time, rather than the name of a file. See Date input formats, for a description of how the timestamp is understood. Tests of the form ‘-newerXt’ are valid but tests of the form ‘-newertY’ are not. 

        For example the test -newerac /tmp/foo  succeeds for all files which have been accessed more recently than /tmp/foo was changed. Here ‘X’ is ‘a’ and ‘Y’ is ‘c’.

        Not all files have a known birth time. If ‘Y’ is ‘b’ and the birth time of reference is not available, find  exits with an explanatory error message. If ‘X’ is ‘b’ and we do not know the birth time the file currently being considered, the test simply fails (that is, it behaves like -false  does).

        Some operating systems (for example, most implementations of Unix) do not support file birth times. Some others, for example NetBSD-3.1, do. Even on operating systems which support file birth times, the information may not be available for specific files. For example, under NetBSD, file birth times are supported on UFS2 file systems, but not UFS1 file systems.

    There are two ways to list files in /usr modified after February 1 of the current year. One uses ‘-newermt’:

         find /usr -newermt "Feb 1"

    The other way of doing this works on the versions of find before 4.3.3:

         touch -t 02010000 /tmp/stamp$$
         find /usr -newer /tmp/stamp$$
         rm -f /tmp/stamp$$

    — Test: -anewer file
    — Test: -cnewer file
    — Test: -newer file

        True if the file was last accessed (or its status changed, or it was modified) more recently than file was modified. These tests are affected by ‘-follow’ only if ‘-follow’ comes before them on the command line. See Symbolic Links, for more information on ‘-follow’. As an example, to list any files modified since /bin/sh was last modified:

                  find . -newer /bin/sh

    — Test: -used n

        True if the file was last accessed n days after its status was last changed. Useful for finding files that are not being used, and could perhaps be archived or removed to save disk space.

Expressions can be use to select files created or modified during contain intervals, for example files that are at least one week old (7 days) but less then 30 days old. You can combine the predicates like this:

	find . -mtime +30 -a -mtime -7 -print0

Note: If you use parameters with find command in scripts be careful when -mtime parameter is equal zero ( -mtime +0 ). Earlier versions of GNU find incorrectly interpret the following expression:

find -mtime +0 -mtime -1

which should be equivalent to

find  -mtime -1

but does not produce any files...

Removing files by age can have nasty side effects if you transferee file from one computer to another preserving timestamp and the target directory is controlled by cron job that delete files of certain age. For example the scp command run as root , retains the file attributes from the original file.

To avoid this problem you can use a script that inventoried the files in the directory and diff the content of the directory the contents from previous days to determine when each file actually appeared.  You can use also ctime instead of mtime. For copied file this is the date and time that was created of the target system. In such cases using ctime in the cron job is safer. 


Part 5: Using -exec option and xargs with find

Find is capable to perform various actions on the files or directories that are found. Among most commonly used actions are

    print prints the names of the files on standard output (usually enabled by default); this list can be piped to another script for post processing. This is the default action and you can usually omit it.
        -print0 ( GNU find only) tells find to use the null character (\0) instead of whitespace as the output delimiter between pathnames found. This is a safer option if you files can contain blanks or other special character. It is recommended to use the -print0 argument to find if you use -exec command or xargs (the -0 argument is needed in xargs.).
    -ls This is almost identical to ls -l listing. Listing can be postprocessed by AWK or Perl scripts.
    -delete  Delete files or directories; true if removal succeeded. If the removal failed, an error message is issued. As deleted files are difficult to recover, you are strongly advised  test the command substituting it first with -ls, especially if you try to delete files from system or other directories. Five minutes testing often saves five hours frantic recovery effort ;-). This option also can be used for deleting files with "strange" characters in names.  First, determine the file or directory's inode. For example

    ls -lhi *.html

    Then use the find command with the inode of the troublemaker, for example:

    find . -type f -inum 31467125 -exec mv {} new_name.html \;

    To simply delete such a file you can use option -delete of GNU find:

    find . -type f -inum 314167125 -delete

    The same trick can be used for renaming files with special characters in names. See  How to rename files with special characters in names.
     
    -exec  command Executes the specified command for each file found. This is the most powerful (and thus dangerous) option that find provides. This option is more suitable for executing relatively simple commands. {}  species the current file. {} is expanded to a relative path starting with the name of one of the starting directories, rather than just the basename of the matched file. You can use several instances of {} in the command: GNU find  replaces {} wherever it appears. For more complex things post processing of output of find command with xargs  is a safer option as you first write it wont to a file, check the output and only then run xargs on file preventing running some potentially irreversible action on files beyond the subset you intended to process...
    -execdir  command ; attempt to create a more safe version of -exec. Same semantic as -exec but it always provides absolute path to the file and it checks the path for safety (dot in the path is really dangerous in this case).

        Execute command; true if zero status is returned. find  takes all arguments after -execto be part of the command until an argument consisting of ;is reached. It replaces the string {}by the current file name being processed everywhere it occurs in the command. Both of these constructions need to be escaped (with a \) or quoted to protect them from expansion by the shell. The command is executed in the directory in which find  was run.

        For example, to compare each C header file in or below the current directory with the file /tmp/master:

        find . -name '*.h' -execdir diff -u '{}' /tmp/master ';'

        If you use -execdir, you must ensure that the $PATH variable contains only absolute directory names. Having an empty element in $Pathos explicitly including .(or any other non-absolute name) is insecure. GNU find will refuse to run if you use -expectorant it thinks your $PATH setting is insecure.

While print option is pretty benign, the exec option is a powerful and dangerous tool. Administrator folklore contains many stories of wiping out important filesystems by misunderstanding of file option. There the rule No.1: always test find command containing exec using -ls option instead of exec to see if the files selected are the files you really wish to process.
Always test find command containing exec by using -ls instead of -exec to see if the files selected are the files you wish to process. This is especially important if the exec option contains rm command or some other destructive command.

Find is able to execute one or more commands for each file it has found with the -exec option. Unfortunately, one cannot simply enter the command. You need to remember two syntactic tricks:

    The command that you want to execute need to contain a special macro argument {}, which will be replaced by the matched filename on each invocation of -exec predicate.
    You need to specify \; (or ';' ) at the end of the command. (If the \ is left out, the shell will interpret the ; as the end of the find command.) . For example, the following two commands are equivalent:

    find . -name "*rc.conf" -exec chmod o+r {} \;
    find . -name "*rc.conf" -exec chmod o+r '{} ;' 

    In case {} macro parameter is the last item in the command then it should be a space between the {} and the \;. For example:

    find . -type d -exec ls -ld {} \; 

If you attempt to make changes that involve system directories it is better to do it in two stages. first create a file with the list of changes using find and verify that it is accurate. Then use xargs with option -p (see below) to process this file.

In case of deletion of the file GNU find  has option -delete which is safer then "-exec /bin/rm {} \;". For example find / -name core -delete 
In case of deletion of the file GNU find has option -delete which is safer then " -exec /bin/rm {} \; ". For example find / -name core -delete

There is classic problem of using rm in case you have filenames with spaces, for example files that migrated to Unix filesystem from Windows where, unfortunately, using spaces in filenames is a common practice. For example you might need to delete all documents that ends with "doc copy":

find /mnt/zip -name "*doc copy"

there are three ways to solve this problem:

    Use option -delete  (GNU find only)
    Rename all files replacing spaces with underscore.
    Use quote over argument in rm command
        find /mnt/zip -name "*doc copy" -exec rm "{}" \;
    Use xargs with option -0 and find  command with option -print0 (see discussion below, in section devoted to xargs):

find /mnt/zip -name "*prefs copy" -print0 | xargs -0 rm

Again it is better to experiment first to see if everything is right if you deal with important files. Five minutes of testing can save five or more hours of desperate attempts to recover accidentally deleted files.

Here are examples of "good practices" of using find. We will use chmod as the base of examples. Many people do not think about commands like chmod or chown as particularly dangerous, but applied to root filesystem they can be pretty devastating. Please note that we first get to the target directory using cd and only then are using find  command with "." (dot) argument. This avoids such unpleased situation as typing "/ etc" instead of "/etc" or "/etc" instead of etc (the intention was to get to local etc directory but string "/etc" is hardwired in sysadmin brains and this slip costs many sysadmins tremendous pain):

    Test command:

    find . -type f -ls

    Final command:

    find . -type f -exec chmod 500 {} ';'

The command bellow search in the current directory and all sub directories and change permissions of each file as specified. Here an additional danger is connected with being in a wring directory.

    Test command:

    find . -name "*rc.conf"  -ls

    Final command:

    find . -name "*rc.conf"  -exec chmod o+r {} \;

This command will search in the current directory and all sub directories. All files named *rc.conf will be processed by the chmod -o+r command. The argument {} is a macro that expands to each found file. The \; argument indicates the -exec argument has ended. You can use ';' instead:

find . -name "*rc.conf" -exec chmod o+r {} ';' 

The end results of this command is all *rc.conf files have read bit set in "other" permissions.

The find  command is commonly used to remove core files that are more than a few 24-hour periods (days) old. These core files are copies of the actual memory image of a running program when the program dies unexpectedly. They can be huge, so occasionally trimming them is wise:

    Test command:

    find . -name core -ctime +4 -ls

    Final command:

    find . -name core -ctime +4 -exec /bin/rm -f {} \;

For grep the /dev/null  argument can by used to show the name of the file before the text that is found. Without it, only the text found is printed. An equivalent mechanism in GNU find  is to use the "-H" or "--with-filename" option to grep:

find /tmp -exec grep "search	string" {} /dev/null \; -print

An alternative to -exec option is piping output into xargs command which we will discuss in the next section.
Feeding find  output to pipes with xargs

One of the biggest limitations of the -exec option (or predicate with the side effect to be more correct) is that it can only run the specified command on one file at a time. The xargs command solves this problem by enabling users to run a single command on many files at one time. In general, it is much faster to run one command on many files, because this cuts down on the number of invocations of particular command/utility.
Note: Print0 with print list of filenames with null character (\0) instead of whitespace as the output delimiter between pathnames found. This is a safer option if files can contain blanks or other special characters if you use find  with xargs (the -0 argument is needed in xargs.). 

For example often one needs to find files containing a specific pattern in multiple directories one can use an exec option in find 

 find . -type f -exec grep -iH '/bin/ksh' {} \; 

But there is more elegant and more Unix-like way of accomplishing the same task using xargs and pipes. You can use the xargs to read the output of find  and build a pipeline that invokes grep. This way, grep is called only four or five times even though it might check through 200 or 300 files. By default, xargs always appends the list of filenames to the end of the specified command, so using it with grep and most other Unix command is pretty natural:

find . -type f -print | xargs grep -il 'bin/ksh' 

This gave the same output a lot faster (-l option in grep prints only the names of files with matching lines, separated by NEWLINE characters. Does not repeat the names of files when the pattern is found more than once.)

Also the xargs is used with grep it will be getting multiple filenames, it will automatically include the filename of any file that contains a match. Still option -H for grep (or addition /dev/null to the list of files) is recommended as the last "chunk" of filenames can contain a single file.

When used in combination, find, grep, and xargs are a potent team to help find files lost or misplaced anywhere in the UNIX file system. I encourage you to experiment further. You can use time to find the difference in speed with -exec option vs. xargs in the following way:

time find /usr/src -name "*.html" -exec grep -H "foo" {} ';' | wc -l
time find /usr/src -name "*.html" | xargs grep -l "foo" | wc -l

xargs works considerably faster. The difference becomes even greater when more complex commands are run and the list of files is longer.

Two other useful options for xargs are the -p option, which makes xargs interactive, and the -n xargs option, which makes xargs run the specified command with only N number of arguments. Option -0 is often used with -print0

This combination is useful if you need to operate on filenames with spaces. If you add option -print0 to find command and option -0 to xargs command, you can avoid the danger to processing wrong file(s) xargs:

find /mnt/zip -name "*prefs copy" -print0 | xargs -0 rm

Using option -p you can provide manual confirmation of each action. The reason is that xargs runs the specified command on the filenames from its standard input, so interactive commands such as cp -i, mv -i, and rm -i don't work right.

So when you run the command first time you can use this option as a safety valve. After several operations with confirmation you can cancel it and run without option -p. The -p option solves that problem. In the preceding example, the -p option would have made the command safe because I could answer yes or no to each file. Thus, the command I typed was the following:

find /mnt/zip -name "*prefs copy" -print0 | xargs -p rm

Many users frequently ask why xargs  should be used when shell command substitution archives the same results. Take a look at this example:

grep foo ´find /usr/src/linux -name "*.html"´

The drawback with commands such as this is that if the set of files returned by find  is longer than the system's command-line length limit, the command will fail. The xargs  approach gets around this problem because xargs  runs the command as many times as is required, instead of just once.

People are doing pretty complex staff this way. For example (Ubuntu Forums, March 23rd, 2010)

    FakeOutdoorsman

        I'm trying to convert Nikon NEF images to jpg. Usually I use find and xargs for batch processes like this for example:

        Code:

        find . -name "*.flac" -exec basename \{\} .flac \; | xargs -i ffmpeg \
        	-i \{\}.flac -acodec libvorbis -aq 3 \{\}.ogg

        However, my latest attempt is giving me no output because I can't seem to get xargs to work with pipes. An individual set of commands works:

        Code:

        dcraw -w -c MEY_7046.NEF | convert - -resize 25% MEY_7046.jpg exiftool \
        	-overwrite_original -TagsFromFile MEY_7046.NEF MEY_7046.jpg dcraw -z MEY_7046.jpg

        A nice set of commands, but not yet practical for converting a DVD with multiple directories. My truncated find-isized version does nothing:

        Code:

        find . -name "*.NEF" -exec basename \{\} .NEF \; | xargs -i dcraw -w -c \{\}.NEF | convert - -resize 25% \{\}.jpg

        Any ideas of where I'm going wrong?

    diesch:

        That pipes the output of all the dcraw runs together into one convert call.

        Try

        Code:

        find . -name "*.NEF" -exec basename \{\} .NEF \; | xargs -i sh -c 'dcraw -w -c $0.NEF | convert - resize 25% $0.jpg'

In this example you can also use -0 argument to xargs.

But ability of xargs to use multiple argument can be a source of the problems too. For example

find . -type f -name "*.java" | xargs tar cvf myfile.tar

Here the attempt is made to create a backup of all java files in the current tree: But if the list length for xargs to invoke the tar command is too  big, xargs will split it into multiple command, and subsequent tar commands will overwrite previous tar archives. As a result archive will contain a fraction of files, but without testing you might discover that too late.

To solve this problem you can use either file (tar can read a list of files from the file using option -T) or option "-r" which tells tar to append to the archive (option '-c' means "create"):.

find . -type f -name "*.java" | xargs tar rvf myfile.tar

Gotchas

Exec option in find  command is a very sharp tool. Below we'll present some of the horror stories (see also Typical Errors In Using Find). Such errors are often made under time pressure. Please remember that 5 minutes of testing usually can save five or more hours of desperate attempts to recover from the results incorrectly run find  command.
Please remember that 5 minutes of testing usually can save five or more hours of desperate attempts to recover from the results incorrectly run find  command.

Typically "find blunders" are often committed when a complex find  command that changes the files in a certain subtree using rm, chown, or chmod command is constructed and run without any testing. Sometimes the directories that are used contain symbolic links to directories in other part of filesystem and "find start running wild" on subtree that you never intended it to run. Sometimes the pattern that you use has unintended side effect. Sometimes it just a silly typo. Life of sysadmin is a complex one so little testing does wonders in preventing nasty surprises form overconfidence in your own abilities :-).

Here are some pretty telling examples:

    From: jerry@incc.com (Jerry Rocteur)

        Organization: InCC.com Perwez Belgium

        Horror story,

        I sent one of my support guys to do an Oracle update in Madrid.

        As instructed he created a new user called esf and changed the files in /u/appl to owner esf, however in doing so he *must* have cocked up his find  command, the command was:

         find /u/appl -user appl -exec chown esf {} \;

        He rang me up to tell me there was a problem, I logged in via x25 and about 75% of files on system belonged to owner esf.

        VERY little worked on system. What a mess, it took me a while and I came up with a brain wave to fix it but it really screwed up the system.

        Moral: be *very* careful of find execs, get the syntax right!!!!

    Maroo 07.01.09 at 4:46 pm

        I issued the following command on a BackOffice Trading Box in an attempt to clean out a user’s directory. But issued it in the /local. The command ended up taking out the Application mounted SAN directory and the /local directory.

            find . -name "foo.log*" -exec ls -l {} \; | cut -f2 -d "/" | while

            read NAME; do gzip -c $NAME > $NAME.gz; rm -r $NAME;

            done

        Took out the server for an entire day.

    Ville 07.14.09 at 12:17 am

        I run a periodic (daily) script on a BSD system to clean out a temp directory for joe (the editor). Anything older than a day gets wiped out. For some historical reason the temp directory sits in /usr/joe-cache rather than in, for instance, /usr/local/joe-cache or /var/joe-cache or /tmp/joe-cache. The first version of the line in the script that does the deleting looked like this:

        find /usr/joe-cache/.* -maxdepth 1 -mtime +1 -exec rm {} \;

        Good thing the only files in /usr were two symlinks that were neither mission critical nor difficult to recreate as the above also matches “/usr/edit-cache/..” In the above the rather extraneous (joe doesn’t save backup files in sub-directories) “-maxdepth 1″ saved the entire /usr from being wiped out!

        The revised version:

        find -E /usr/joe-cache/ -regex '/usr/joe-cache/\.?.+$' -maxdepth 1 -mtime +1 -exec rm {} \;

        .. which matches files beginning with a dot within “/usr/joe-cache”, but won’t match “/usr/joe-cache/..”

        Lesson learned: always test find statements with “-print” before adding “-exec rm {} \;”.

Part 6: Finding SUID/SGUID files
Unix permissions model 	SUID attribute 	Principle of Least Privilege 	chmod command 	 

Suid root refers to a special attribute called set user id. This attribute allows the program to do functions not normally allowed for owner of the file to perform.

Low level networking routines, controlling graphical display functions, changing passwords, and logging in are all examples of programs that rely on executing their functions as a user that is not restricted by standard file permissions. While many programs need this functionality, the program must be bug free in only allowing the user to do the function the program was designed for. Every SUID root program represents a potential security problem.  Attempts of rogue users to install SUID programs in thier home directories are best blocked by using nosuid mounting option for /home partition.

The first step in controlling SUID root programs is to have a baseline, the list of all SUID program in the system. This can be achieved quite easily by using find:

find / -type f -perm +6000 -exec ls -l {} \; > suid.list 

Notes:

    This will find both set user id and set group id programs.
    Please note that this program does not detect all SUID programs available on the system, there might be directories perversely set to permissions 000
    Attempts of rogue users to install SUID programs in thier home directories are best blocked by using nosuid mounting option for /home partition.
    Solaris used to have a script called fix-modes written by Casper Dik that changed permission in a more reasonable, secure set. Such script can be created for any OS. For example on most modem systems it does not make sense to preserve SUID attribute uucp and similar "never used" programs.
    Most modern Unixes block usage of SUID attrbute on shell scripts.

Above command is using GNU find and executes ls command. You can use option -ls instead but output will be slightly different. Solaris POSIX find command different:

find / -type f \( -perm -4000 -o -perm -2000 
	\) -exec ls -l {} \; 

This command will find all the SUID programs on a system and pipes the commands to a file called suid.list. The next step in controlling SUID root programs is to analyze which programs should not be SUID root or can be removed without impeding system functionality. An obvious example of something that should not be SUID root is /usr/X11R6/bin/SuperProbe.  This is a program merely used for testing purposes.

'chmod -s /usr/X11R6/bin/SuperProbe'	

Other programs that are unneeded to be SUID root include anything in the svgalib  hierarchy. This library itself is buggy and nothing that depends on it should be SUID root in a secure system.

Here is an example of minimized suid.lst though perhaps a little too overzealous. For example, the functionality that does not exist with this setup is ability to use ping and traceroute by a regular users and this is a typical security paranoia overkill. It can be compensated by controlling access to those program via sudo but this is road to nowhere.

But in any case minimization of the number of SUID program is task worth trying. It is excessive zeal that hurts...

See also

    Unix permissions model
    SUID attribute
    Principle of Least Privilege
    Unix chmod command
    Linux Security HOWTO Files and Filesystem Security
    Download from CERIAS for fix-modes  (historical value only)
    There is a Sun BluePrints[tm] paper discussing fix-modes.
        Sun BluePrints[tm] Program
         
    Fix-modes is incorporated in JumpStart[tm] Architecture and Security Scripts (JASS) toolkit.
        Solaris Security Toolkit (JASS)
        Sun Blueprint for JASS
         
    Fix-modes were a part of the Titan OS hardening tool.

Part 7: Finding World Writable, Abandoned and other Abnormal Files

Often system administrators need to detect "abnormal" files (e.g., world writable files, files with no valid owner and/or group, SetUID files, files with unusual permissions, sizes, names, or dates).  We already discusses a very important case of SUID/SGUID files. Now let's concentrate of other possibilities. Here is several simplified (usually you need to avoid traversing special filesystem and NFS mounts) but potentially useful examples:

    To find all world writable directories:

    find / -perm -0002 -type d -print

    To find all world writable files:

    find / -perm -0002 -type f -print

    Find both files and directories (exclude symbolic links which produce false positives)

    find / -perm -2 ! -type l -ls

    Find files with messed UID or GID (possible as the result untarting files as root on a server with different structure of user accounts and groups): 

    find / -nouser -o -nogroup -print

    to fix

    find / -nouser -o -nogroup -print0 | xargs -0 chgrp root:root

    Find broken symbolic links

        $ find / -type l -print | perl -nle '-e || print'; 

    Note: This command starts at the topmost directory (/) and lists all links (-type l -print) that the perl interpreter determines broken links (-nle '-e || print').  You can further pipe the output through xargs and use the rm -f {} if you want to delete such symbolic links.
     
    Clean out core dumps and temporary files

    find . \( -name a.out -o -name '*.o' -o -name 'core' \) -exec rm {} \;

Those examples are pretty simplistic as in "real life" you need to be able to block traversing of NFS and other non-native filesystems and avoid getting to special memory-mapped filesystems like proc.  Earlier versions of GNU find were allergic to proc filesystem. Here is one useful approach  described in from Wayne Pollock's  Unix-Linux find Command Tutorial

    As a system administrator you can use find to locate suspicious files (e.g., world writable files, files with no valid owner and/or group, SetUID files, files with unusual permissions, sizes, names, or dates).  Here's a final more complex example (which I save as a shell script):

    find / -noleaf -wholename '/proc' -prune \
         -o -wholename '/sys' -prune \
         -o -wholename '/dev' -prune \
         -o -wholename '/windows-C-Drive' -prune \
         -o -perm -2 ! -type l  ! -type s \
         ! \( -type d -perm -1000 \) -print

    This says to search the whole system, skipping the directories /proc, /sys, /dev, and /windows-C-Drive (presumably a Windows partition on a dual-booted computer).  The Gnu -noleaf option tells find not to assume all remaining mounted filesystems are Unix file systems (you might have a mounted CD for instance).  The "-o" is the Boolean OR operator, and " !" is the Boolean NOT operator (applies to the following criteria).

Another and potentially simpler and faster approach is to use -fstype type  predicate. It is true if the filesystem to which the file belongs is of type type. For example on Solaris mounted local filesystems have type ufs  (Solaris 10 added zfs). For AIX local filesystem is jfs or jfs2 (journalled file system). 

But sometimes the same server uses several types of local filesystems (for example ext3 and reisner). In this case you can use predicate OR and create expression that covers each used filesystem or use generic predicate local and in certain circumstances predicate  mount. 

Part 9: Using find for backups

The find command lets you copy the entire contents of a directory while preserving the permissions, times, and ownership of every file and subdirectory. Because find capabilities to specify complex criteria for files it can create a perfect list of files for cpio, tar, pax and another archiver to backup

Fortunately find has several options that are very useful for structuring the backup:

    -mount Don't descend directories on other filesystems. An alternate name for -xdev, for compatibility with some other versions of find.
    -fstype type File is on a filesystem of type type. The valid filesystem types vary among different versions of Unix; an incomplete list of filesystem types that are accepted on some version of Unix or another is: ufs, 4.2, 4.3, nfs, tmp, mfs, S51K, S52K. You can use -printf with the %F directive to see the types of your filesystems.
    -type c File is of type c:
        b block (buffered) special
        c character (unbuffered) special
        d directory
        p named pipe (FIFO)
        f regular file
        l symbolic link; this is never true if the -L option or the
        -follow option is in effect, unless the symbolic link is
        broken. If you want to search for symbolic links when -L
        is in effect, use -xtype.
        s socket
        D door (Solaris)

The typical usage is to combine find and the cpio command, as the latter accepts the list of files via standard input.  Tar can do this too with -T - option.  Typically each mount point is backed up in a separate tar or cpio archive. 

cd /usr

find /usr -mount fstype ext3 - | cpio -pdumv /backup/usr080124.cpi

or, using tar:

find /usr -mount fstype ext3 -print0 | tar -null -cvzf /backup/usr080124.tgz

It is also possible to do incremental backups using -newer option

find /usr -newer /backup/usr080124.tgz -mount fstype ext3 -print0 | tar -null -cvzf /backup/usr_delta080124.tgz

You can also try to avoid errors in backing up named pipes, devises, etc  using more complex traversal expressions, for example

    find / -mount -fstype ext3 \( -type f -or -type l \) > /tmp/root_list.txt

The problem here is with hard linked files. That that is problem of tar not find. The cpio command is a more sophisticated backup tool than tar. It is harder to use, but is capable of copying special files (such as devices and links) consistently, and will accept wildcard characters when listing the files to be archived.

On higher level you might benefit from exclusion of all files that are not changes in RPMs from which system was installed.  This is the approach taken by  backup built-in in YAST (it uses tar, not cpio). While tar cannot accept the list of files as standard input it has the -T option which can be used to specify the location of file with list of files to be tarred". Here is how this option is described in the manual:

    Instead of giving the names of files or archive members on the command line, you can put the names into a file, and then use the ‘--files-from=file-of-names’ (‘-T file-of-names’) option to tar. Give the name of the file which contains the list of files to include as the argument to ‘--files-from’. In the list, the file names should be separated by newlines. You will frequently use this option when you have generated the list of files to archive with the find utility. 

    ... ... ...

    In the file list given by ‘-T’ option, any file name beginning with ‘-’ character is considered a tar option and is processed accordingly.(14) For example, the common use of this feature is to change to another directory by specifying ‘-C’ option:

    $ cat list
    -C/etc
    passwd
    hosts
    -C/lib
    libc.a
    $ tar -c -f foo.tar --files-from list

For example if we want to archive file that has size less then 1000 we can first create of list of such files using find and then use tar to created an archive.

find .  -size -1K -print > /etc/small-files
tar -cvzT /etc/small-files -f little.tgz

You can also compress the archive with gzip of the fly:

    tar -zPvcf backup.tar.gz -T list_of_files_to_be_tarred_or_list_of_locations

You will want to use the ‘--label=archive-label’ (‘-V archive-label’) option to give the archive a volume label, so you can tell what this archive is even if the label falls off the tape, or anything like that.

Unless the file system you are dumping is guaranteed to fit on one volume, you might need to use the ‘--multi-volume’ (‘-M’) option.

Like find,  tar has an option of that prevent it from crossing the filesystem (partition) boundaries:  ‘--one-file-system’ option to prevent  from crossing file system boundaries when storing (sub)directories.

It also has the ‘--incremental’ (‘-G’) option  (see section Using tar to Perform Incremental Dumps).
Find has several useful for backups filesystem Traversal Options

The options ‘-H’, ‘-L’ or ‘-P’ may be specified at the start of the command line (if none of these is specified, ‘-P’ is assumed). If you specify more than one of these options, the last one specified takes effect (the ‘-follow’ option is equivalent to ‘-L’).

    -P Never follow symbolic links (this is the default), except in the case of the ‘-xtype’ predicate.
     
    -L Always follow symbolic links, except in the case of the ‘-xtype’ predicate.
     
    -H Follow symbolic links specified in the list of files to search, or which are otherwise specified on the command line.

If find would follow a symbolic link, but cannot for any reason (for example, because it has insufficient permissions or the link is broken), it falls back on using the properties of the symbolic link itself. Symbolic Links for a more complete description of how symbolic links are handled.
— Option: -maxdepth levels
 

    Descend at most levels (a non-negative integer) levels of directories below the command line arguments. ‘-maxdepth 0’ means only apply the tests and actions to the command line arguments.

— Option: -mindepth levels
 

    Do not apply any tests or actions at levels less than levels (a non-negative integer). ‘-mindepth 1’ means process all files except the command line arguments.

— Option: -depth
 

    Process each directory's contents before the directory itself. Doing this is a good idea when producing lists of files to archive with cpio or tar. If a directory does not have write permission for its owner, its contents can still be restored from the archive since the directory's permissions are restored after its contents.

— Option: -d
 

    This is a deprecated synonym for ‘-depth’, for compatibility with Mac OS X, FreeBSD and OpenBSD. The ‘-depth’ option is a POSIX feature, so it is better to use that.

— Action: -prune
 

    If the file is a directory, do not descend into it. The result is true. For example, to skip the directory src/emacs and all files and directories under it, and print the names of the other files found:

              find . -wholename './src/emacs' -prune -o -print

    The above command will not print ./src/emacs among its list of results. This however is not due to the effect of the ‘-prune’ action (which only prevents further descent, it doesn't make sure we ignore that item). Instead, this effect is due to the use of ‘-o’. Since the left hand side of the “or” condition has succeeded for ./src/emacs, it is not necessary to evaluate the right-hand-side (‘-print’) at all for this particular file. If you wanted to print that directory name you could use either an extra ‘-print’ action:

              find . -wholename './src/emacs' -prune -print -o -print

    or use the comma operator:

              find . -wholename './src/emacs' -prune , -print

    If the ‘-depth’ option is in effect, the subdirectories will have already been visited in any case. Hence ‘-prune’ has no effect in this case.

    Because ‘-delete’ implies ‘-depth’, using ‘-prune’ in combination with ‘-delete’ may well result in the deletion of more files than you intended.

— Action: -quit
 

    Exit immediately (with return value zero if no errors have occurred). This is different to ‘-prune’ because ‘-prune’ only applies to the contents of pruned directories, whilt ‘-quit’ simply makes find stop immediately. No child processes will be left running, but no more files specified on the command line will be processed. For example, find /tmp/foo /tmp/bar -print -quit will print only ‘/tmp/foo’. Any command lines which have been built by ‘-exec ... \+’ or ‘-execdir ... \+’ are invoked before the program is exited.

— Option: -noleaf
 

    Do not optimize by assuming that directories contain 2 fewer subdirectories than their hard link count. This option is needed when searching filesystems that do not follow the Unix directory-link convention, such as CD-ROM or MS-DOS filesystems or AFS volume mount points. Each directory on a normal Unix filesystem has at least 2 hard links: its name and its . entry. Additionally, its subdirectories (if any) each have a .. entry linked to that directory. When find is examining a directory, after it has statted 2 fewer subdirectories than the directory's link count, it knows that the rest of the entries in the directory are non-directories (leaf files in the directory tree). If only the files' names need to be examined, there is no need to stat them; this gives a significant increase in search speed.

— Option: -ignore_readdir_race
 

    If a file disappears after its name has been read from a directory but before find gets around to examining the file with stat, don't issue an error message. If you don't specify this option, an error message will be issued. This option can be useful in system scripts (cron scripts, for example) that examine areas of the filesystem that change frequently (mail queues, temporary directories, and so forth), because this scenario is common for those sorts of directories. Completely silencing error messages from find is undesirable, so this option neatly solves the problem. There is no way to search one part of the filesystem with this option on and part of it with this option off, though. When this option is turned on and find discovers that one of the start-point files specified on the command line does not exist, no error message will be issued.

— Option: -noignore_readdir_race
 

    This option reverses the effect of the ‘-ignore_readdir_race’ option.

 
Next: Combining Primaries With Operators, Previous: Directories, Up: Finding Files
2.10 Filesystems

A filesystem is a section of a disk, either on the local host or mounted from a remote host over a network. Searching network filesystems can be slow, so it is common to make find avoid them.

There are two ways to avoid searching certain filesystems. One way is to tell find to only search one filesystem:
— Option: -xdev
— Option: -mount
 

    Don't descend directories on other filesystems. These options are synonyms.

The other way is to check the type of filesystem each file is on, and not descend directories that are on undesirable filesystem types:
— Test: -fstype type
 

    True if the file is on a filesystem of type type. The valid filesystem types vary among different versions of Unix; an incomplete list of filesystem types that are accepted on some version of Unix or another is:

              ext2 ext3 proc sysfs ufs 4.2 4.3 nfs tmp mfs S51K S52K

    You can use ‘-printf’ with the ‘%F’ directive to see the types of your filesystems. The ‘%D’ directive shows the device number. See Print File Information. ‘-fstype’ is usually used with ‘-prune’ to avoid searching remote filesystems (see Directories).


 Part 10: Examples of Usage of Unix Find Command
See also 	Recommended Links 	Man pages 	Unix Find Tutorial

    Script with examples written by Viktor Chuyko
    Unix-Linux find command mini-tutorial
    Find tutorial from grymoire.com
    Advanced techniques for using the UNIX find command
    Some examples of using Unix find command.
    Find examples from www.wagoneers.com
    Examples from Sun manpage

Script with examples written by Viktor Chuyko

Script started on Fri Oct  1 10:31:16 1999
hills{501}vchuyk01: cat myfind
#!/usr/bin/bash
# EWORK8
# Script:myfind 
# Written by Viktor Chuyko
#
# This program demonstrates the features of find command
#
# This script is written in the bash scripting language
#
#
#

It is great Mr. Wostner's idea to run 'date' command because the programs
seaching the entire system with find command take incredibly long time
to output the result.
I could not get the output of myfind program inside script. It took 
a number of hours.
I used another method to submit current assignment. Sorry about that.

echo
date

echo
echo "Next is listing of the files starting from home dir, that have
size 50k or less and have extention html."
find . \( -size 100 -o -size -100 \)  -name '*.html' \
   -exec  ls -l {} \;  2> /dev/null 

echo
echo "The following is the number of symbolic links starting from root:"
find /students -type l -print 2> /dev/null |wc -l   

echo
echo "Below is listing of all directories starting from root that have
sticky bit (t or T) set."

find / -type d  -perm -1000  -exec ls -ld {} \; 2> /dev/null

echo
echo "Here is creating \"junk\" directory."
find ~ -type d -exec mkdir junk {} \; 2> /dev/null
echo
ls -ld ~/junk
echo
echo "I created the following empty files in junk directory:"
echo
find ~/junk -exec touch ~/junk/cart{1,2,3,4,5,6} {} \; 2> /dev/null

find ~/junk  -name 'cart[1-6]' -exec ls -l {} \; 2> /dev/null
echo
echo "After renaming and removing some of the files from junk directory
long listing of all the files in that directory looks like:"
echo
find ~/junk  -name 'cart1' -exec mv {} ~/junk/A \; 
find ~/junk  -name 'cart2' -exec mv {} ~/junk/B \;
find ~/junk  -name 'cart3' -exec mv {} ~/junk/C \;

#ls -l ~/junk

find ~/junk  -name 'cart[4-6]' -exec rm {}  \;
find ~/junk   -name "*" -exec ls -l {} \; 
#ls -l ~/junk

echo "Following is to say good bye."
echo
date
hills{502}vchuyk01: myfind

Fri Oct  1 10:31:37 PDT 1999

Next is listing of the files starting from home dir, that have
size 50k or less and have extention html.
-rwxr-xr-x   1 vchuyk01   c73762         824 Sep 30 13:01 ./public_html/index.html
-rw-r--r--   1 vchuyk01   c73762         524 Sep 30 13:01 ./public_html/project_outline.html
-rwxr--r--   1 vchuyk01   c73762        4439 Sep 30 13:01 ./public_html/command.html
-rw-r--r--   1 vchuyk01   c73762         508 Sep 30 13:01 ./public_html/project.html
-rw-r--r--   1 vchuyk01   c73762         391 Sep 30 13:01 ./public_html/cut.html
-rw-r--r--   1 vchuyk01   c73762         335 Sep 30 13:01 ./public_html/paste.html
-rw-------   1 vchuyk01   c73762         586 Sep 30 13:01 ./public_html/lynx_bookmarks.html
-rw-------   1 vchuyk01   c73762         169 Sep 30 13:01 ./public_html/read.html
-rw-------   1 vchuyk01   c32324        1004 Sep 30 13:01 ./lynx_bookmarks.html
-rw-------   1 vchuyk01   c32324         304 Sep 30 13:01 ./project_outline.html

The following is the number of symbolic links starting from root:
144

Below is listing of all directories starting from root that have
sticky bit (t or T) set.
d-wxrw--wt   3 3395       users         2048 Aug 10  1997 /opt/video/DVC_SDK/examples/xcam
drwxrwxrwt  13 bin        bin         571392 Sep 30 21:42 /tmp
drwxrwxrwt   2 root       root          2048 Sep 30 21:43 /var/spool/cron/tmp
drwxrwsrwt   2 daemon     daemon        2048 Sep  4 09:32 /var/spool/calendar
drwxrwxrwt   6 root       bin           2048 Sep 22 22:25 /var/opt/dce/rpc/local
drwxr-xr-t   2 root       sys             96 Sep 22 22:24 /var/opt/dce/rpc/local/00475
drwxr-xr-t   3 root       root            96 Sep 22 22:25 /var/opt/dce/rpc/local/01191
drwxr-xr-t   2 root       root            96 Sep 22 22:25 /var/opt/dce/rpc/local/01191/c-3
drwxrwxrwt   2 root       sys           2048 Sep 22 22:25 /var/opt/dce/rpc/local/s-0
drwxrwxrwt   2 root       sys             96 Sep 22 22:25 /var/opt/dce/rpc/local/s-3
drwxrwxrwt   2 root       bin             96 May 30  1998 /var/opt/dce/security/creds
drwxrwxrwt   2 root       bin             96 Jun 10  1996 /var/opt/dce/svc
drwxr-xr-t   2 sabensoh   cisdept       1024 Aug 28 15:33 /pub/cis/cis110c/lab4
drwxr-xr-t   2 sabensoh   cisdept       1024 Aug 28 15:32 /pub/cis/cis110c/lab6
drwxr-xr-t   2 sabensoh   cisdept       1024 Aug 28 15:23 /pub/cis/cis110c/life1
drwxr-xr-t   2 sabensoh   cisdept       1024 Aug 28 15:24 /pub/cis/cis110c/life2
drwxr-xr-t   2 sabensoh   cisdept       1024 Aug 28 15:27 /pub/cis/cis110c/life3
drwxr-xr-t   2 sabensoh   cisdept       1024 Aug 28 15:28 /pub/cis/cis110c/lab3

Here is creating "junk" directory.

drwx--S---   2 vchuyk01   c73762        2048 Sep 30 21:37 /students/vchuyk01/junk

I created the following empty files in junk directory:

-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/cart1
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/cart2
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/cart3
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/cart4
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/cart5
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/cart6

After renaming and removing some of the files from junk directory
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/B
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/C
-rw-------   1 vchuyk01   c73762           0 Sep 30 21:43 /students/vchuyk01/junk/A
Following is to say good bye.


hills{503}vchuyk01: exit
exit

script done on Fri Oct  1 10:31:47 1999

Unix-Linux find command mini-tutorial
Unix-Linux find command mini-tutorial

    When specifying time with find  options such as -mmin  (minutes) or -mtime  (24 hour periods, starting from now), you can specify a number "n" to mean exactly n, "-n" to mean less than n, and "+n" to mean more than n. 2  For example:

    find . -mtime 0   # find files modified within the past 24 hours
    find . -mtime -1  # find files modified within the past 24 hours
    find . -mtime 1   # find files modified between 24 and 48 hours ago
    find . -mtime +1  # find files modified more than 48 hours ago
    find . -mmin +5 -mmin -10 # find files modifed between 6 and 9 minutes ago

    The following displays non-hidden (no leading dot) files in the current directory only (no subdirectopries), with an arbitrary output format (see the man page for the dozens of possibilities with the -printf action):

    find . -maxdepth 1 -name '[!.]*' -printf 'Name: %16f Size: %6s\n'

    As a system administrator you can use find to locate suspicious files (e.g., world writable files, files with no valid owner and/or group, SetUID files, files with unusual permissions, sizes, names, or dates).  Here's a final more complex example (which I save as a shell script):

    find / -noleaf -wholename '/proc' -prune \
         -o -wholename '/sys' -prune \
         -o -wholename '/dev' -prune \
         -o -wholename '/windows-C-Drive' -prune \
         -o -perm -2 ! -type l  ! -type s \
         ! \( -type d -perm -1000 \) -print

    This says to seach the whole system, skipping the directories /proc, /sys, /dev, and /windows-C-Drive (presumably a Windows partition on a dual-booted computer).  The -noleaf option tells find to not assume all remaining mounted filesystems are Unix file systems (you might have a mounted CD for instance).  The "-o" is the Boolean OR operator, and "!" is the Boolean NOT operator (applies to the following criteria).  So this criteria says to locate files that are world writable ("-perm -2") and NOT symlinks ("! -type l") and NOT sockets ("! -type s") and NOT directories with the sticky (or text) bit set ("! \( -type d -perm -1000 \)").  (Symlinks, sockets and directories with the sticky bit set are often world-writable and generally not suspicious.)

Find tutorial from grymoire.com
Find tutorial from grymoire.com

    Looking for files by type

    If you are only interested in files of a certain type, use the -type argument, followed by one of the following characters:

    +---------------------------------------------------+
        |Character	 Meaning				|
        +---------------------------------------------------+
        |b		 Block special file (see mknode(8))	|
        |c		 Character special file (see mknode(8)) |
        |d		 Directory				|
        |f		 Plain file				|
        |p		 Named Pipe File			|
        |l		 Symbolic link				|
        |s		 Socket					|
        +---------------------------------------------------+

    Unless you are a system administrator, the important types are directories, plain files, or symbolic links (i.e. types d, f, or l).

    Using the -type option, another way to recursively list files is:

        find . -type f -print | xargs ls -l
         

    It can be difficult to keep track of all of the symbolic links in a directory. The next command will find all of the symbolic links in your home directory, and print the files your symbolic links point to.

        find . -type l -print | xargs ls -ld | awk '{print $10}'

    Looking for files by sizes

    Find has several options that take a decimal integer. One such argument is -size. The number after this argument is the size of the files in disk blocks. Unfortunately, this is a very vague number. Earlier versions of Unix used disk blocks of 512 bytes. Newer versions allow larger block sizes, so a "block" of 512 bytes is misleading.

    This confusion is aggravated when the command ls -s is used. The -s option lists the size of the file in blocks. If the command is "/usr/bin/ls," the block size is 1024 bytes. If the command is "/usr/5bin/ls," the block size is 512 bytes.

    Let me confuse you some more. The following shows the two versions of ls:

        % /usr/bin/ls -sl file
        14 -rwxr-xr-x 1 barnett 13443 Jul 25 23:27 file
        % /usr/5bin/ls -sl file
        28 -rwxr-xr-x 1 barnett staff 13443 Jul 25 23:27 file
         

    Can you guess what block size should be specified so that find prints this file? The correct command is:

        find . -size 27 -print
         

    because the actual size is between 26 and 16 blocks of 512 bytes each. As you can see, "ls -s" is not an accurate number for find. You can put a c after the number, and specify the size in bytes,

    To search for files using a range of file sizes, a minus or plus sign can be specified before the number. The minus sign means "less than," and the plus sign means "greater than." This next example lists all files that are greater than 10,000 bytes, but less than 32,000 bytes:

        find . -size +10000c -size -32000c -print
         

    When more than one qualifier is given, both must be true.

    Searching for old files
    If you want to find a file that is 7 days old, use the -mtime option:

        find . -mtime 7 -print
         

    An alternate way is to specify a range of times:

        find . -mtime +6 -mtime -8 -print
         

    Mtime is the last modified time of a file. You can also think of this as the creation time of the file, as Unix does not distinguish between creation and modification. If you want to look for files that have not been used, check the access time with the -atime argument. A command to list all files that have not be read in thirty days or more is

        find . -type f -atime +30 -print
         

    It is difficult to find directories that have not been accessed because the find command modifies the directory's access time.

    There is another time associated with each file, called the ctime, accessed with the -ctime option. This will have a more recent value if the owner, group, permission or number of links is changed, while the file itself does not. If you want to search for files with a specific number of links, use the -linksoption.

    Searching for files by permission

    Find can look for files with a specific permission. It uses an octal number for these permissions. The string rw-rw-r--, indicates you and members of your group have read and write permission, while the world has read only priviledge. The same permissions, when expressed as an octal number, is 664. To find all "*.o" files with the above permission, use:

        find . -name *.o -perm 664 -print
         

    If you want to see if you have any directories with world write permission, use:

        find . -type d -perm 777 -print
         

    This only matches the exact combination of permissions. If you wanted to find all directories with group write permission, there are several combinations that can match. You could list each combination, but find allows you to specify a pattern that can be bit-wise ANDed with the permissions of the file. Simply put a minus sign before the octal value. The group write permission bit is octal 20, so the following negative value:

        find . -perm -20 -print
         

    will match the following common permissions:

    +-------------------------+
    		 |Permission   Octal value |
    		 +-------------------------+
    		 |rwxrwxrwx    777	   |
    		 |rwxrwxr-x    775	   |
    		 |rw-rw-rw-    666	   |
    		 |rw-rw-r--    664	   |
    		 |rw-rw----    660	   |
    		 +-------------------------+

    If you wanted to look for files that you can execute, (i.e. shell scripts or programs), you want to match the pattern "--x------," by typing:

        find . -perm -100 -print
         

    When the -perm argument has a minus sign, all of the permission bits are examined, including the set user ID bits.

    Owners and groups

    Often you need to look for a file that has certain permissions and belonging to a certain user or group. This is done with the -user and -group search options. To find all files that are set user ID to root, use:

        find . -user root -perm -4000 -print
         

    To find all files that are set group ID to staff, use:

        find . -group staff -perm -2000 -print
         

    Instead of using a name or group in /etc/passwd or /etc/group, you can use a number:

        find . -user 0 -perm -4000 -print
        find . -group 10 -perm -2000 -print
         

    Often, when a user leaves a site, their account is deleted, but their files are still on the computer. A system manager can use the -nouser or -nogroup to find files with an unknown user or group ID.

    Find and commands

    So far, after find has found a file, all it has done is printed the filename. It can do much more than that, but the syntax can get hairy. Using xargs saves you this mental effort, but it isn't always the best solution.

    If you want a recursive listing, find's output can be piped into | xargs ls -l but it is more efficient to use the built in -ls option:

        find . -ls
         

    This is similar to the command:

        find . -print | xargs ls -gilds
         

    You could also use ls -R command, but that would be too easy.

     

    Find and Cpio
    Find also understands cpio, and supports the -cpio and -ncpio commands:

        find . -depth -cpio >/dev/rmt0
        find . -depth -ncpio >/dev/rmt0
         

    which do the same as

        find . -depth -print | cpio -oB >/dev/rmt0
        find . -depth -print | cpio -ocB >/dev/rmt0

    Using Find to Execute Commands

    I have already discussed how to use xargs to execute commands. Find can execute commands directly. The syntax is peculiar, which is one reasons I recommend xargs. The syntax of the -exec option allows you to execute any command, including another find command. If you consider that for a moment, you realize that find needs some way to distinguish the command it's executing from its own arguments. The obvious choice is to use the same end of command character as the shell (i.e. the semicolon). Since the shell normally uses the semicolon itself, it is necessary to "escape" the character with a backslash or quotes. There is one more special argument that find treats differently: {}. These two characters are used as the variable whose name is the file find found. Don't bother re-reading that last line. An example will clarify the usage. The following is a trivial case, and uses the -exec option to mimic the "-print' option.

        find . -exec echo {} ;
         

    The C shell uses the characters { and }, but doesn't change {}, which is why it is not necessary to quote these characters. The semicolon must be quoted, however. Quotes can be used instead of a backslash:

        find . -exec echo {} ';'
         

    as both will pass the semicolon past the shell to the find command. As I said before, find can even call find. If you wanted to list every symbolic link in every directory owned by group "staff" you could execute:

        find `pwd` -group staff -exec find {} -type l -print ;
         

    To search for all files with group write permission, and remove the permission, you can use

        find . -perm -20 -exec chmod g-w {} ;
         

    or

        find . -perm -20 -print | xargs chmod g-w
         

    The difference between -exec and xargs are subtle. The first one will execute the program once per file, while xargs can handle several files with each process. However, xargs may have problems with files that contain embedded spaces.

    Occasionally people create a strange file that they can't delete. This could be caused by accidentally creating a file with a space or some control character in the name. Find and -exec can delete this file, while xargs could not. In this case, use ls -il to list the files and i-nodes, and use the -inum option with -exec to delete the file:

        find . -inum 31246 -exec rm [] ';'
         

    If you wish, you can use -ok which does the same as -exec, except the program asks you first to confirm the action before executing the command. It is a good idea to be cautious when using find, because the program can make a mistake into a disaster. When in doubt, use echo as the command. Or send the output to a file and examine the file before using the file as input to xargs. This is how I discovered that find can only use one {} in the arguments to -exec. I wanted to rename some files using "-exec mv {} {}.orig" but I learned that I have to write a shell script that I told find to execute.

    File comparisons
    Whenever I upgraded to a new version of Unix, one common problem was making sure I maintained all of the changes made to the standard release of Unix. Previously, I did a ls -lt in each directory, and then I examined the modification date. The files that were changed has an obviously newer date that the original programs. Even so, finding every change was tedious, as there were dozens of directories to be searched.

    A better solution is to create a file as the first step in upgrading. I usually call this FirstFile. Find has a -newer option that tests each file and compares the modification date to the newer file. If you then wanted to list all files in /usr that need to be saved when the operating system is upgraded, use:

        find /usr -newer /usr/FirstFile -print
         

    This could then be used to create a tar or cpio file that would be restored after the upgrade.

    Expressions
    Find allows complex expressions. To negate a test, put a ! before the option. Since the C shell interprets this command, it must be escaped. To find all files the same age or older than "FirstFile," use

        find /usr ! -newer /FirstFile -print
         

    The "and" function is performed by the -a option. This is not needed, as two or more options are ANDed automatically. The "or" function is done with the -o option. Parenthesis can be used to add precedence. These must also be escaped. If you wanted to print object and "a.out" files that are older than 7 days, use:

        find . ( -name a.out -o -name *.o ) -print

    Keeping find from going too far

    The most painful aspect of a large NFS environment is avoiding the access of files on NFS servers that are down. Find is particularly sensitive to this, because it is very easy to access dozens of machines with a single command. If find tries to explore a file server that happens to be down, it will time out. It is important to understand how to prevent find from going too far.

    The important option in this case is -prune. This option confuses people because it is always true. It has a side-effect that is important. If the file being looked at is a directory, it will not travel down the directory. Here is an example that lists all files in a directory but does not look at any files in subdirectories under the top level:

        find * -type f -print -o -type d -prune
         

    This will print all plain files and prune the search at all directories. To print files except for those in a Source Code Control Directories, use:

        find . -print -o -name SCCS -prune
         

    If the -o option is excluded, the SCCS directory will be printed along with the other files.

    Another useful combination is using -prune with -fstype or -xdev. Fstype tests for file system types, and expects an argument like nfs or 4.2. The later refers to the file system introduced in the 4.2 release of the Berkeley Software Distribution. To limit find to files only on a local disk or disks, use the clause -fstype 4.2 -prune or -o -fstype nfs -prune. If you needed to limit the search to one particular disk partition, use -xdev, The later is very useful if you want to help a congested disk partition, and wanted to look for all files greater than 40 blocks on the current disk partition;

        find . -size -40 -xdev -print

Advanced techniques for using the UNIX find command
Advanced techniques for using the UNIX find command by Bill Zimmerly

    28 Mar 2006 (IBM DeveloperWorks)
    Clean out temporary files

    You can use find to clean directories and subdirectories of the temporary files generated during normal use, thereby saving disk space. To do so, use the following command:

    $ find . \( -name a.out -o -name '*.o' -o -name 'core' \) -exec rm {} \;


    File masks identifying the file types to be removed are located between the parentheses; each file mask is preceded by -name. This list can be extended to include any temporary file types you can come up with that need to be cleaned off the system. In the course of compiling and linking code, programmers and their tools generate file types like those shown in the example: a.out, *.o, and core. Other users have similar commonly generated temporary files and can edit the command accordingly, using file masks like *.tmp, *.junk, and so on. You might also find it useful to put the command into a script called clean, which you can execute whenever you need to clean a directory.

    Copy a directory's contents

    The find command lets you copy the entire contents of a directory while preserving the permissions, times, and ownership of every file and subdirectory. To do so, combine find and the cpio command, like this:


    Listing 2. Combining the find and cpio command
     

    $ cd /path/to/source/dir

    $ find . | cpio -pdumv /path/to/destination/dir


    The cpio command is a copy command designed to copy files into and out of a cpio or tar archive, automatically preserving permissions, times, and ownership of files and subdirectories.

    List the first lines of text files

    Some people use the first line of every text file as a heading or description of the file's contents. A report that lists the filenames and first line of each text file can make sifting through several hundred text files a lot easier. The following command lists the first line in every text file in your home directory in a report, ready to be examined at your leisure with the less command:

    Listing 3. The less command
     

    $ find $HOME/. -name *.txt -exec head -n 1 -v {} \; > report.txt

    $ less < report.txt


    Maintain LOG and TMP file storage spaces

    To maintain LOG and TMP file storage space for applications that generate a lot of these files, you can put the following commands into a cron job that runs daily:


    Listing 4. Maintaining LOG and TMP file storage spaces
     

    $ find $LOGDIR -type d -mtime +0 -exec compress -r {} \;

    $ find $LOGDIR -type d -mtime +5 -exec rm -f {} \;


    The first command runs all the directories (-type d) found in the $LOGDIR directory wherein a file's data has been modified within the last 24 hours (-mtime +0) and compresses them (compress -r {}) to save disk space. The second command deletes them (rm -f {}) if they are more than a work-week old (-mtime +5), to increase the free space on the disk. In this way, the cron job automatically keeps the directories for a window of time that you specify.

    Copy complex directory trees

    If you want to copy complex directory trees from one machine to another while preserving copy permissions and the User ID and Group ID (UID and GID -- numbers used by the operating system to mark files for ownership purposes), and leaving user files alone, find and cpio once again come to the rescue:

    Listing 5. Maintaining LOG and TMP file storage spaces
     

    $ cd /source/directory

    $ find . -depth -print | cpio -o -O /target/directory


    Find links that point to nothing

    To find links that point to nothing, use the perl interpreter with find, like this:

    $ find / -type l -print | perl -nle '-e || print';


    This command starts at the topmost directory (/) and lists all links (-type l -print) that the perl interpreter determines point to nothing (-nle '-e || print') -- see the Resources section for more information regarding this tip from the Unix Guru Universe site. You can further pipe the output through the rm -f {} functionality if you want to delete the files. Perl is, of course, one of the many powerful interpretive language tools also found in most UNIX toolkits. 

Some examples of using Unix find command
Some examples of using Unix find command.

    Introduction
    Search for file with a specific name in a set of files (-name)
    How to apply a unix command to a set of file (-exec).
    How to apply a complex selection of files (-o and -a).
    How to search for a string in a selection of files (-exec grep ...).
    How to apply a complex selection of files (-o and -a).

        find /usr/src -not \( -name "*,v" -o -name ".*,v" \) '{}' \; -print 

    This command will search in the /usr/src directory and all sub directories. All files that are of the form '*,v' and '.*,v' are excluded. Important arguments to note are:
        -not means the negation of the expression that follows
        \( means the start of a complex expression.
        \) means the end of a complex expression.
        -o means a logical or of a complex expression.
        In this case the complex expression is all files like '*,v' or '.*,v'

    The above example is shows how to select all file that are not part of the RCS system. This is important when you want go through a source tree and modify all the source files... but ... you don't want to affect the RCS version control files.
     

Find examples from www.wagoneers.com

find examples from www.wagoneers.com

    sudo find / -type f -name *.jpg  -exec cp {} . \;

    find . -type f -size +10000 -exec ls -al {} \;
    find . -atime +1 -type f -exec mv {} TMP \; # mv files older then 1 day to dir TMP
    find . -name "-F" -exec rm {} \;   # a script error created a file called -F
    find . -exec grep -i "vds admin" {} \;
    find . \! -name "*.Z" -exec compress -f {} \;
    find . -type f \! -name "*.Z" \! -name ".comment" -print | tee -a /tmp/list
    find . -name *.ini
    find . -exec chmod 775 {} \;
    find . -user xuser1 -exec chown -R user2 {} \;
    find . -name ebtcom*
    find . -name mkbook
    find . -exec grep PW0 {} \;
    find . -exec grep -i "pw0" {} \;
    find . -atime +6
    find . -atime +6 -exec ll | more
    find . -atime +6 -exec ll | more \;
    find . -atime +6 -exec ll \;
    find . -atime +6 -exec ls \;
    find . -atime +30 -exec ls \;
    find . -atime +30 -exec ls \; | wc -l
    find . -name auth*
    find . -exec grep -i plotme10 {};
    find . -exec grep -i plotme10 {} \;
    find . -ls -exec grep 'PLOT_FORMAT 22' {} \;
    find . -print -exec grep 'PLOT_FORMAT 22' {} \;
    find . -print -exec grep 'PLOT_FORMAT' {} \;
    find . -print -exec grep 'PLOT_FORMAT' {} \;
    find ./machbook -exec chown 184 {} \;
    find . \! -name '*.Z' -exec compress {} \;
    find . \! -name "*.Z" -exec compress -f {} \;
    find /raid/03c/ecn -xdev -type f -print
    find /raid/03c/ecn -xdev -path -type f -print
    find / -name .ssh* -print | tee -a ssh-stuff
    find . -name "*font*"
    find . -name hpmcad*
    find . -name *fnt*
    find . -name hp_mcad* -print
    find . -grep Pld {} \;
    find . -exec grep Pld {} \;
    find . -exec grep Pld {} \;
    find . -exec grep PENWIDTH {} \; | more
    find . -name config.pro
    find . -name config.pro
    find /raid -type d ".local_sd_customize" -print
    find /raid -type d -name ".local_sd_customize" -print
    find /raid -type d -name ".local_sd_customize" -ok cp /raid/04d/MCAD-apps/I_Custom/SD_custom/site_sd_customize/user_filer_project_dirs {} \;
    find /raid -type d -name ".local_sd_customize" -exec cp /raid/04d/MCAD-apps/I_Custom/SD_custom/site_sd_customize/user_filer_project_dirs {} \;
    find . -name xeroxrelease
    find . -exec grep xeroxrelease {} \;
    find . -name xeroxrelease
    find . -name xeroxrelease* -print 2>/dev/null
    find . -name "*release*" 2>/dev/null
    find / -name "*xerox*" 2>/dev/null
    find . -exec grep -i xeroxrelease {} \;
    find . -print -exec grep -i xeroxrelease {} \;
    find . -print -exec grep -i xeroxrelease {} \; > xeroxrel.lis
    find . -exec grep -i xeroxrel {} \;
    find . -print -exec grep -i xeroxrel {} \;
    find . -print -exec grep -i xeroxrel {} \; | more
    find /raid/03c/inwork -xdev -type f -print >> /raid/04d/user_scripts/prt_list.tmp
    find . -exec grep '31.53' {} \;
    find . -ls -exec grep "31/.53" {} \; > this.lis
    find . -print -exec grep "31/.53" {} \; > this.lis
    find . -print -exec grep 31.53 {} \; > this.lis
    find . -exec grep -i pen {} /;
    find . -exec grep -i pen {} \;
    find . -print -exec grep -i pen {} \; | more
    find . -exec grep -i pen {} \;
    find . -atime +6 -exec ll | more \;
    find . -atime +6 -exec ll \;
    find . -atime +6 -exec ls \;
    find . -atime +30 -exec ls \;
    find . -atime +30 -exec ls \; | wc -l
    find . \! -name '*.Z' -exec compress -f {} \;
    find . -name 'cache*' -depth -exec rm {} \;
    find . -name 'cache*' -depth -print | tee -a /tmp/cachefiles
    find . -name 'cache[0-9][0-9]*' -depth -print | tee -a /tmp/cachefiles
    find . -name 'hp_catfile' 'hp_catlock' -depth -print | tee -a /tmp/hp.cats
    find . -name 'hp_catfile' -name 'hp_catlock' -depth -print | tee -a /tmp/hp.cats
    find . -name 'hp_cat*' -depth -print | tee -a /tmp/hp.cats
    find . -name 'hp_cat[fl]*' -depth -print | tee -a /tmp/hp.cats
    find /raid -name 'hp_cat[fl]*' -depth -print
    find . \! -name '*.Z' -exec compress -f {} \;
    find . -name '*' -exec compress -f {} \;
    find . -xdev -name "wshp1*" -print
    find . -xdev -name "wagoneer*" -print
    find . -name "xcmd" -depth -print
    find /usr/contrib/src -name "xcmd" -depth -print
    find /raid -type d -name ".local_sd_customize" -exec ls {} \;
    find /raid -type d -name ".local_sd_customize" \
       -exec cp /raid/04d/MCAD-apps/I_Custom/SD_custom/site_sd_customize/user_filer_project_dirs {} \;
     

Examples from Sun manpage
docs.sun.com man pages section 1 User Commands

    Print all files  with the given extension:

        find . -name "*.c" -type f -print 

        find /usr/local -name "*.html" -type f -print

    Print all file that exceed a certain size and were modified long ago (to clear some space):

        find / -size +1000 -mtime +30 -exec ls -l {} \;

        To report all files starting in the directories "/mydir1" and "/mydir2" larger than 2000 blocks (about 1000K) AND that have not been accessed in over 30 days, enter:

          find /mydir1 /mydir2 -size +2000 -atime +30 -print

    Removes unnecessary files that are older than two weeks old, but doesn't descend NFS mounted file systems while searching:

        find / \( -name a.out -o -name core  -o -name '#*#' \) -type f -atime +14 -exec rm -f {} \; -o -fstype nfs -prune

    Fix permissions for a group of files with given extension

        find /usr/local -name "*.html" -type f -exec chmod 644 {} \;

        find htdocs cgi-bin -name "*.cgi" -type f -exec chmod 755 {} \;

        This command searches through the "htdocs" and "cgi-bin" directories for files that end with the extension ".cgi". When these files are found, their permission is changed to mode 755 (rwxr-xr-x). This example shows that the find command can easily search through multiple sub-directories (htdocs, cgi-bin) at one time.

    SUID games (see above):

        find / \( -perm -006 -o -perm -007 \) \( ! -type -l \) -ls # find all files that have wrong permission

        find / \( -nogroup -o -noname \) -ls

        Does a difference on all file names that have SUID or SGID permissions against a pre-defined list of files

        find / \( -perm 2000 -o -perm 4000 \)  -type f -ls | diff - suidfiles.ref

    To remove (with prompting) all files starting in the "/mydir" directory that have not been accessed in over 100 days, enter:

      find /mydir -atime +100 -ok rm {} \;

    To show a long listing starting in "/mydir" of files not modified in over 20 days OR not accessed in over 40 days, enter:

      find /mydir \(-mtime +20 -o -atime +40\) -exec ls -l {} \;

    To list and remove all regular files named "core" starting in the directory "/prog" that are larger than 500K, enter:

      find /prog -type f -size +1000 -print -name core -exec rm {} \;

    How to apply a complex selection of files (-o and -a).

        find /usr/src -not \( -name "*,v" -o -name ".*,v" \) '{}' \; -print

        This command will search in the /usr/src directory and all sub directories. All files that are of the form '*,v' and '.*,v' are excluded. Important arguments to note are:

            -not( ! in Solaris) means the negation of the expression that follows
            \( means the start of a complex expression.
            \) means the end of a complex expression.
            -o means a logical or of a complex expression.
            In this case the complex expression is all files like '*,v' or '.*,v'

        The above example is shows how to select all file that are not part of the RCS system. This is important when you want go through a source tree and modify all the source files... but ... you don't want to affect the RCS version control files.

    How to search for a string in a selection of files (-exec grep ...).

        find . -exec grep "www.athabasca" '{}' \; -print

        This command will search in the current directory and all sub directories. All files that contain the string will have their path printed to standard output.

        If you want to just find each file then pass it on for processing use the -q grep option. This finds the first occurrance of the search string. It then signals success to find and find continues searching for more files.

            find . -exec grep -q "www.athabasca" '{}' \; -print

        This command is very important for process a series of files that contain a specific string. You can then process each file appropriately. An example is find all html files with the string "www.athabascau.ca". You can then process the files with a sed script to change those occurrances of "www.athabascau.ca" with "intra.athabascau.ca".

O'Reilly - Safari Books Online - 0131018833 - HP-UX 11i System Administration Handbook and Toolkit, Second Edition

    Finding Files of a Specific Type

    You may want to perform a find operation to produce a list of files only and not include directories in the operation. The following find is similar to what we performed earlier, but this time it produces a list of files only. This is achieved by specifying that we are looking for type f for files:

    # find /home -type f -print 

    You can search for a variety of different types such as f for a file as shown in the example, b for a block special file, l for a symbolic link, and so on.

    Find Empty Files and Directories

    A useful test when performing a find operation is to locate empty files. The following example searches for all empty files and directories on the system with the -empty operator that is available on some UNIX variants, including Linux. This is only a partial output because it's so long:

    # find / -empty -print 
     

    All the files and directories listed as a result of this find operation are empty. The long listing of /auto shown as part of the example, confirms this fact. Keep in mind that -empty is not available on all UNIX variants.

    Finding Files By Name, Size, and Both Name and Size

    Let's perform a couple of independent finds and then combine the criteria of the finds. The finds in the following example are performed on a small, desktop system. This allows me to search the entire system for files meeting various criteria. You may be working on a much larger, more elaborate system, so use caution when searching the entire system for files. You may slow down other users for a long period of time, depending on the number of files on the system both locally and accessible over the network.

    First, let's find for all files on the system ending in.c with the command below:

    # find / -name *.c -print 

    You can see from this find that there are many files on the system ending in.c. I included only the beginning and end of this search because the entire output would be too long.

    I also ran this command and piped the output to wc, which showed 1737 files on the system ending in.c, as shown in the following example:

    # find / -name *.c | wc 
       1737    1737   77044 
    # 

    Now we can search for all files on the system greater than 500,000 characters in size with the find command below:

    # find / -size +500000c -print 

    I also ran this command and piped the output to wc, which showed 215 files on the system with a size greater than 500,000 characters, as shown in the following example:

    # find / -size +500000c -print | wc 
        215     215    6281 
    # 

    Let's now combine the two commands and see how many of the files on the system ending in.c are also greater than 500,000 characters in size:

    # find / -name *.c -size +500000c -print 
    /usr/src/drivers/scsi/advansys.c 
    # 

    Of the 1737 files on the system ending in.c and the 215 files greater than 500,000 characters in size, only one file, advansys.c, meets both criteria. There is an implied and in the previous find command. We could have explicitly specified an and; however, it is implied in the find command. The find did indeed result in files that end in.c and are greater than 500,000 characters. The upcoming find uses the or operator, which is not implied.

    What if we wanted to find both files ending in.c and.o that are greater than 500000 characters in size? We could use the -o operator which would "or" the files ending in.c and.o. The following example shows this find operation:

    find / -size +500000c \(  -name *.c -o -name *.a \) -print 
    find / -size +500000c \(  -name *.c -o -name *.a \) -print | wc 


    # find / -size +500000c \( -name *.c -o -name *.a \) -print 

    The two file extensions for which we are searching are placed in parentheses. A backslash is required before the open and close parentheses because the parentheses have meaning to the shell and we want them to be used only to specify the precedence in our find command and not to be used by the shell. The result of this find shows that many files ending in.a and.c meet the criteria of greater than 500,000 characters.

    Let's now pipe the output of this commnd to wc to see precisely the number of files ending in either.c or.o and have a size greater than 500,000 characters:

    # find / -size +500000c \( -name *.c -o -name *.a \) -print | wc 
         39      39     982 
    # 

    Of the 39 files that meet the criteria, we know that 38 ended in.a because our earlier example showed that only one file ending in.c met the criteria.

    Finding Files By Owner, Type, and Permissions

    You can find objects on the system owned by particular users and groups. To find all of the objects owned by user "news" on the system, we would use the following command:

    # find / -user news -print 

    Using the -user operator we can specify either the name of the user, in this case "news", or the user identification number. The following example shows performing the same find operation using the user identification number of "news," in this case "9," instead of the name "news":

    # find / -user 9 -print 

    This find operation produced exactly the same results using the name "news" and the user idenfication number "9."

    You can search for a variety of different types such as f for a file, as shown in the example, b for a block special file, l for a symbolic link, and so on. We could add type -d to find only directories belonging "news" as in the following command:

    # find / -user news -type d -perm 775 -print 

    This is another example of using the implied and of find meaning that the find will print items that are both owned by "news" and are directories only.

    Let's now add a specific permission for the directories to our implied and. We'll find only objects belonging to "news" that are directories with a permission of 775 in the following example:


        # find / -user news -type d -perm 775 -print

    We searched for directories belonging to "news" in which both the owner and those in the group have read-write-execute permission, and others have read-execute access. This is a common type of find operation for system administrators to perform - looking for files and directories belonging to a specific user and having specific permissions.


Part 12: Typical Errors In Using Find
See also 	Recommended Links 	Horror stories 	Unix Find Tutorial
Pure stupidity 	Creative uses of rm 	Root deletion protection 	Safe-rm
Executing command in a wrong directory 	Typical Errors In Using Find 	Performing the operation on a wrong computer 	Lack of testing
  	Unix History with some Emphasis on Scripting 	Humor 	Etc

Find is complex and powerful utility and Unix sysadmin folklore contains many example of tremendous damage that sysadmin can do to the system by using find incorrectly.

Probably the most important source of blunders is using  -exec  option without sufficient testing under time pressure. Hurry slowly is one of the saying that are very true for sysadmin. Sometimes your emotional state contribute to the problems: you didn’t have much sleep or your mind was distracted by your personal life problems. In such days it is important to slow down and be extra cautious.

If we try to classify typical blunders in using find they fall into several categories

    Find filesystem traversal errors (errors in specifying file system traversal predicates)
        Inadvertently applying operation to mounted filesystem with write access
        Appling operation to unintended parts of the filesystem tree due to links in the target directory.
        Dot-errors
    Gotchas connected with presence of spaces of special characters in file name
    Not testing potentially destructive command like rm, chmod, chown, etc, especially before execution on a production box.  Such errors are often made under time pressure. Among them
        Unintended mass changes of file ownership.  Those are common when using chown with find so you need to test the command first.
        Running rm command in find without testing
    Pure stupidity

Find filesystem traversal errors

One common mistake in using find command from root directory or other level 2 directory like /var or /opt is that it can contain mounted filesystems with write access. If you intend to make changes only on local filesystem always put -xdev in find command.  That prevent find traversing mounted NFS and other filesystems.  Here is one such story

    If you're doing this using find always put -xdev in:

     find /tmp/ -xdev -fstype 4.2 -type f -atime +5 -exec rm {} \;

    This stops find from working its way down filesystems mounted under /tmp/. If you're using, say, perl you have to stat . and .. and see if they are mounted on the same device. The fstype 4.2 is pure paranoia.

    Needless to say, I once forgot to do this. All was well for some weeks until Convex's version of NQS decided to temporarily mount /mnt under /tmp... Interestingly, only two people noticed. Yes, the chief op. Keeps good backups!

    Other triumphs: I created a list of a user's files that hadn't been accessed for three months and a perl script for him to delete them. Of course, it had to be tested, I mislaid a quote from a print statement... This did turn into a triumph, he only wanted a small fraction of them back so we saved 20 MB.

    I once deleted the only line from within an if.. then statement in rc.local, the sun refused to come up, and it was surprisingly difficult to come up single user with a writeable file system.

    AIX is a whole system of nightmares strung together. If you stray outside of the sort of setup IBM implicitly assume you have (all IBM kit, no non IBM hosts on the network, etc.) you're liable to end up in deep doodoo.

    One thing I would like all vendors to do (I know one or two do) is to give root the option of logging in using another shell. Am I the only one to have mangled a root shell?

    John Rowe

Another common find filesystem traversal error are side effects of performing operations on home or application directories that contain links to other directories, especially to system directories. This is a pretty common mistake and I had committed it myself several time with various, but always unpleasant consequences. Here is one example 

    From: cjc@ulysses.att.com (Chris Calabrese)
    Organization: AT&T Bell Labs, Murray Hill, NJ, USA

    In article <7515@blue.cis.pitt.edu.UUCP> broadley@neurocog.lrdc.pitt.edu writes:
    >On a old decstation 3100 I was deleting last semesters users to try to
    >dig up some disk space, I also deleted some test users at the same time.
    >
    >One user took longer then usual, so I hit control-c and tried ls. "ls: command not found"
    >
    >Turns out that the test user had / as the home directory and the remove user script in ultrix just happily blew away the whole disk.
    >U...~

    Reminds me of a bit of local folk-lore (this happened before I was in the admin group)...

    We have a home-grown admin system that controls accounts on all of our machines.  It has a remove user operation that removes the user from all machines at the same time in the middle of the night.

    Well, one night, the thing goes off and tries to remove a user with the home directory '/'.  All the machines went down, with varying amounts of stuff missing (depending on how soon the script, rm, find, and other importing things were clobbered).

    Nobody knew what what was going on!  The systems were restored from backup, and things seemed to be going OK, until the next night when the remove-user script was fired off by cron again.

    This time, Corporate Security was called in, and the admin group's supervisor was called back from his vacation (I think there's something in there about a helicopter picking the guy up from a rafting trip in the Grand Canyon).

    By chance, somebody checked the cron scripts, and all was well for the next night...
     

Gotchas connected with presence of spaces of special characters in file name

Here is an extreme example of the problems that using blank-delimited names can cause. If the following command is run daily from cron, then any user can remove any file on the system:

     find / -name '#*' -atime +7 -print | xargs rm

To delete other files, for example /u/joeuser/.plan, you could do this:

     eg$ mkdir '#
     '
     eg$ cd '#
     '
     eg$ mkdir u u/joeuser u/joeuser/.plan'
     '
     eg$ echo > u/joeuser/.plan'
     /#foo'
     eg$ cd ..
     eg$ find . -name '#*' -print | xargs echo
     ./# ./# /u/joeuser/.plan /#foo

 
Not testing complex change or deletion using find, especially before execution of production box. 

Such errors are often made under time pressure. See more at  Typical Errors In Using Find. such errors are often reqal mini-disasters and they are often connected with attempts to use find for recursive change of the files in a certain subtree  using rm, chown, or chmod.  Such attempt are dangerous if you do them without testing it using -ls  first to see the set of files to which this operation will be applied. 

If you attempt to make changed that involve system directories it is better to do it in two stages. first create a file with the list of changes using find and verify that it is accurate. Them use xargs to process this file.

You should always use ls -Rl command to test complex rm  -R  commands (  -R, --recursive means process  subdirectories recursively).

Unintended mass changes of files ownership or files permissions are also common when using chown or chmod with find. Here are a couple of examples:

    From: jerry@incc.com (Jerry Rocteur)

        Organization: InCC.com Perwez Belgium

         Horror story,

         I sent one of my support guys to do an Oracle update in Madrid.

         As instructed he created a new user called esf and changed the files  in /u/appl to owner esf, however in doing so he *must* have cocked up his find command, the command was:

         find /u/appl -user appl -exec chown esf {} \;

         He rang me up to tell me there was a problem, I logged in via x25 and  about 75% of files on system belonged to owner esf.

         VERY little worked on system.  What a mess, it took me a while and I came up with a brain wave to  fix it but it really screwed up the system.

         Moral: be *very* careful of find execs, get the syntax right!!!!

    Maroo 07.01.09 at 4:46 pm

        I issued the following command on a BackOffice Trading Box in an attempt to clean out a user’s directory. But issued it in the /local. The command ended up taking out the Application mounted SAN directory and the /local directory.

            find . -name “foo.log*” -exec ls -l {} \; | cut -f2 -d “/” | while read NAME; do gzip -c $NAME > $NAME.gz; rm -r $NAME;

            done

        Took out the server for an entire day.

    Ville 07.14.09 at 12:17 am

        I run a periodic (daily) script on a BSD system to clean out a temp directory for joe (the editor). Anything older than a day gets wiped out. For some historical reason the temp directory sits in /usr/joe-cache rather than in, for instance, /usr/local/joe-cache or /var/joe-cache or /tmp/joe-cache. The first version of the line in the script that does the deleting looked like this:

        find /usr/joe-cache/.* -maxdepth 1 -mtime +1 -exec rm {} \;

        Good thing the only files in /usr were two symlinks that were neither mission critical nor difficult to recreate as the above also matches “/usr/edit-cache/..” In the above the rather extraneous (joe doesn’t save backup files in sub-directories) “-maxdepth 1″ saved the entire /usr from being wiped out!

        The revised version:

        find -E /usr/joe-cache/ -regex '/usr/joe-cache/\.?.+$' -maxdepth 1 -mtime +1 -exec rm {} \;

        .. which matches files beginning with a dot within “/usr/joe-cache”, but won’t match “/usr/joe-cache/..”

        Lesson learned: always test find statements with “-print” before adding “-exec rm {} \;”.

Problems with find were understood for several decades. Here is an amusing description from Unix hater's handbook

    Find
      	

    The most horrifying thing about Unix is that, no matter how many
     times you hit yourself over the head with it, you never quite manage
     to lose consciousness. It just goes on and on.

    —Patrick Sobalvarro

    Losing a file in a large hierarchical filesystem is a common occurrence. (Think of Imelda Marcos trying to find her pink shoes with the red toe ribbon among all her closets.) This problem is now hitting PC and Apple users with the advent of large, cheap disks. To solve this problem computer systems provide programs for finding files that match given criteria, that have a particular name, or type, or were created after a particular date. The Apple Macintosh and Microsoft Windows have powerful file locators that are relatively easy to use and extremely reliable. These file finders were designed with a human user and modern networking in mind. The Unix file finder program, find, wasn’t designed to work with humans, but with cpio —a Unix backup utility program. Find couldn’t anticipate networks or enhancements to the file system such as symbolic links; even after extensive modifications, it still doesn’t work well with either. As a result, despite its importance to humans who’ve misplaced their files, find doesn’t work reliably or predictably.

    The authors of Unix tried to keep find up to date with the rest of Unix, butit is a hard task. Today’s find has special flags for NFS file systems, symbolic links, executing programs, conditionally executing programs if the user types “y,” and even directly archiving the found files in cpio or cpio-c format. Sun Microsystems modified find so that a background daemon builds a database of every file in the entire Unix file system which, for some strange reason, the find command will search if you type “find filename” without any other arguments. (Talk about a security violation!) Despite all of these hacks, find still doesn’t work properly.

    For example, the csh follows symbolic links, but find doesn’t: csh was written at Berkeley (where symbolic links were implemented), but find dates back to the days of AT&T, pre-symlink. At times, the culture clash between East and West produces mass confusion.

        Date: Thu, 28 Jun 1990 18:14 EDT

        From: pgs@crl.dec.com

        Subject: more things to hate about Unix

        To: UNIX-HATERS

        This is one of my favorites. I’m in some directory, and I want to search another directory for files, using find. I do:

        	po> pwd
        	/ath/u1/pgs
        	po> find ~halstead -name "*.trace" -print
            po>

        The files aren’t there. But now:

        po> cd ~halstead
        	po> find . -name "*.trace" -print
        	./learnX/fib-3.trace
        	./learnX/p20xp20.trace
        	./learnX/fib-3i.trace
        	./learnX/fib-5.trace
        	./learnX/p10xp10.trace
            po>

        Hey, now the files are there! Just have to remember to cd to random directories in order to get find to find things in them. What a crock of Unix.

        Poor Halstead must have the entry for his home directory in /etc/passwd pointing off to some symlink that points to his real directory, so some commands work for him and some don’t.
        Why not modify find to make it follow symlinks? Because then any symlink that pointed to a directory higher up the tree would throw find into an endless loop. It would take careful forethought and real programming to design a system that didn’t scan endlessly over the same directory time after time. The simple, Unix, copout solution is just not to follow symlinks, and force the users to deal with the result.

        As networked systems become more and more complicated, these problems are becoming harder and harder:

        Date: Wed, 2 Jan 1991 16:14:27 PST
        From: Ken Harrenstien <klh@nisc.sri.com>
        Subject: Why find doesn’t find anything
        To: UNIX-HATERS

            I just figured out why the “find” program isn’t working for me anymore.

            Even though the syntax is rather clumsy and gross, I have relied on it for a long time to avoid spending hours fruitlessly wandering up and down byzantine directory hierarchies in search of the source for a program that I know exists somewhere (a different place on each machine, of course).

            It turns out that in this brave new world of NFS and symbolic links, “find” is becoming worthless. The so-called file system we have here is a grand spaghetti pile combining several different fileservers with lots and lots of symbolic links hither and thither, none of which the program bothers to follow up on. There isn’t even a switch to request this… the net effect is that enormous chunks of the search space are silently excluded. I finally realized this when my request to search a fairly sizeable directory turned up nothing (not entirely surprising, but it did nothing too fast) and investigation finally revealed that the directory was a symbolic link to some other place.

            I don’t want to have to check out every directory in the tree I give to find—that should be find’s job, dammit. I don’t want to mung the system software every time misfeatures like this come up. I don’t want to waste my time fighting SUN or the entire universe of Unix weeniedom. I don’t want to use Unix. Hate, hate, hate, hate, hate, hate, hate.

            —Ken (feeling slightly better but still pissed)

        Writing a complicated shell script that actually does something with the files that are found produces strange results, a sad result of the shell’s method for passing arguments to commands.

        Date: Sat, 12 Dec 92 01:15:52 PST
        From: Jamie Zawinski <jwz@lucid.com>
        Subject: Q: what’s the opposite of ‘find?’ A: ‘lose.’
        To: UNIX-HATERS

            I wanted to find all .el files in a directory tree that didn’t have a corresponding .elc file. That should be easy. I tried to use find.

            What was I thinking.

            First I tried:

                % find . -name ’*.el’ -exec ’test -f {}c’

                find: incomplete statement

            Oh yeah, I remember, it wants a semicolon.

                % find . -name ’*.el’ -exec ’test -f {}c’ \;

                find: Can’t execute test -f {}c:

                No such file or directory

            Oh, great. It’s not tokenizing that command like most other things

            do.

                % find . -name ’*.el’ -exec test -f {}c \;

            Well, that wasn’t doing anything…

                % find . -name ’*.el’ -exec echo test -f {}c \;

                test -f c

                test -f c

                test -f c

                test -f c

            Great. The shell thinks curly brackets are expendable.

                % find . -name ’*.el’ -exec echo test -f ’{}’c \;

                test -f {}c

                test -f {}c

                test -f {}c

                test -f {}c

                ...

            Huh? Maybe I’m misremembering, and {} isn’t really the magic “substitute this file name” token that find uses. Or maybe…

                % find . -name ’*.el’ \

                -exec echo test -f ’{}’ c \;

                test -f ./bytecomp/bytecomp-runtime.el c

                test -f ./bytecomp/disass.el c

                test -f ./bytecomp/bytecomp.el c

                test -f ./bytecomp/byte-optimize.el c

                ...

            Oh, great. Now what. Let’s see, I could use “sed…”

            Now at this point I should have remembered that profound truism: “Some people, when confronted with a Unix problem, think ‘I know, I’ll use sed.’ Now they have two problems.”

            Five tries and two searches through the sed man page later, I had come up with:

                % echo foo.el | sed ’s/$/c/’

                foo.elc

            and then:

                % find . -name ’*.el’ \

                -exec echo test -f `echo ’{}’ \

                | sed ’s/$/c/’` \;

                test -f c

                test -f c

                test -f c

                ...

            OK, let’s run through the rest of the shell-quoting permutations until we find one that works.

                % find . -name ’*.el’ \

                -exec echo test -f "`echo ’{}’ |\

                sed ’s/$/c/’`" \;

            Variable syntax.

                % find . -name ’*.el’ \

                -exec echo test -f ’`echo "{}" |\

                sed "s/$/c/"`’ \;

                test -f `echo "{}" | sed "s/$/c/"`

                test -f `echo "{}" | sed "s/$/c/"`

                test -f `echo "{}" | sed "s/$/c/"`

                ...

            Hey, that last one was kind of close. Now I just need to…

                % find . -name ’*.el’ \

                -exec echo test -f ’`echo {} | \

                sed "s/$/c/"`’ \;

                test -f `echo {} | sed "s/$/c/"`

                test -f `echo {} | sed "s/$/c/"`

                test -f `echo {} | sed "s/$/c/"`

                ...

            Wait, that’s what I wanted, but why isn’t it substituting the filename for the {}??? Look, there are spaces around it, what do you want, the blood of a goat spilt under a full moon?

            Oh, wait. That backquoted form is one token.

            Maybe I could filter the backquoted form through sed. Um. No.

            So then I spent half a minute trying to figure out how to do something that involved “-exec sh -c …”, and then I finally saw the light,  and wrote some emacs-lisp code to do it. It was easy. It was fast. It worked.

            I was happy. I thought it was over.

            But then in the shower this morning I thought of a way to do it. I couldn’t stop myself. I tried and tried, but the perversity of the task had pulled me in, preying on my morbid fascination. It had the same attraction that the Scribe implementation of Towers of Hanoi has. It only took me 12 tries to get it right. It only spawns two processes per file in the directory tree we're iterating over. It’s the Unix Way!

                % find . -name ’*.el’ -print \

                | sed ’s/^/FOO=/’|\

                sed ’s/$/; if [ ! -f \ ${FOO}c ]; then \

                echo \ $FOO ; fi/’ | sh

            BWAAAAAHH HAAAAHH HAAAAHH HAAAAHH

            HAAAAHH HAAAAHH HAAAAHH HAAAAHH HAAAAHH!!!!

            —Jamie

Prev | Contents | Next


Part 13: Summary

Clearly, your use of the UNIX find command is limited only by your knowledge and creativity.

The find command has a lot of options, and to get the full power out of find, xargs, and grep, you need to experiment.

Among other things you can specify:

    where to search (pathname). Find understands multiple start points like in
    find /usr /bin /sbin /opt -name sar
    Matching criteria, for example:
        name of the file(s) (-name). Can be a simple regex.
        -type what type of file to search for ( d -- directories, f -- files, l -- links)
        -atime n File was accessed "n" 24-hour periods (days) ago
        -mtime n File was modified "n" 24-hour periods (days) ago
        -size n File is "n" 512-byte blocks big
        -fstype typ Specifies filesystem type: 4.2 or nfs
        -name nam The filename is "nam"
        -user usr The file's owner is "usr"
        -group grp The file's group owner is "grp"
        -perm p The file's access mode is "p" (integer or symbolic expression)
    Actions
        -print display pathname (default)
        -exec how to process the files found ( {} expands to current found file )
    Combine matching criteria (predicated) into complex expressions using logical operations -o and -a (default binding) of predicates specified.

Selected Examples
Option 	Meaning 	Example
-atime n

-atime +n

-atime -n

-size
	True if file was accessed n 24-hour periods (days) ago (n), accessed more then n 24-hour periods (days) ago(+n) or less than n 24-hour periods (days) ago (-n) 	

    -mtime +7 Matches files modified more than 7 24-hour periods (days) ago
    -atime -2 Matches files accessed less than 2 24-hour periods (days) ago
    -size +100 Matches files larger than 100 blocks (50K)

-ctime n 	True if the file was created n 24-hour periods (days) ago. 	find . -ctime +30 -type f -exec rm {} ';'
-exec command 	Execute command. 	find . -mtime -2 -type f -exec mv {} ../Spam_collector \;
-mtime n 	True if file was modified n 24-hour periods (days) ago. 	find . -mtime -2 -type f -exec mv {} ../Spam_collector \;
-name pattern 	True if filename matches pattern. 	
-print 	Print names of files found. 	
-type c 	True if file is of type c 	find . -mtime -2 -type f -exec mv {} ../Spam_collector \;
-user name 	True if file is owned by user name. 	

Multiple options are joined by AND by default. OR may be specified with the -o flag and the use of grouped parentheses. For example, to match all files modified more than 90 24-hour periods (days) ago or accessed more than 30 24-hour periods (days) ago, use

\( -mtime +90 -o -atime +30 \)

NOT should be specified with a backslash before exclamation point. For example, to match all files ending in .txt except the file starting with "a-z", use:

\! -name "[a-z]*" -name "*.txt"



